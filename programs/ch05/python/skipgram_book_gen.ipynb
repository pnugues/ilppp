{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple implementation of skipgrams with negative sampling\n",
    "Author: Pierre Nugues\n",
    "\n",
    "Adapted from _Distributed Representations of Words and Phrases and their Compositionality_, Sect. 2.2, by Mikolov et al. 2013."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Embedding, Lambda, Average, GlobalAveragePooling1D, Dot, Input, Reshape, Activation\n",
    "import regex as re\n",
    "import os\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "from tqdm import tqdm\n",
    "from random import shuffle, randint\n",
    "from collections import Counter\n",
    "import math, random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embedding size, context size, and negative counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "w_size = 2\n",
    "c_size = w_size * 2 + 1\n",
    "K_NEG = 5\n",
    "t = 1e-3\n",
    "power = 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select a dataset and execute locally or on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'homer'  # 'homer' dickens' 'selma' 'big'\n",
    "colab = False # On my machine or on colab\n",
    "debug = False\n",
    "DOWNSAMPLING = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if colab:\n",
    "    BASE_PATH = '/content/drive/My Drive/Colab Notebooks/'\n",
    "else:\n",
    "    BASE_PATH = '../../../'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read the files from a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(dir, suffix):\n",
    "    \"\"\"\n",
    "    Returns all the files in a folder ending with suffix\n",
    "    :param dir:\n",
    "    :param suffix:\n",
    "    :return: the list of file names\n",
    "    \"\"\"\n",
    "    files = []\n",
    "    for file in os.listdir(dir):\n",
    "        if file.endswith(suffix):\n",
    "            files.append(file)\n",
    "    return files\n",
    "\n",
    "\n",
    "def load_corpus(path):\n",
    "    files = get_files(path, 'txt')\n",
    "    files = [path + file for file in files]\n",
    "    print(files)\n",
    "    text = ''\n",
    "    for file in files:\n",
    "        text += open(file).read()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'homer':\n",
    "    #text = 'Sing, O goddess, the anger of Achilles son of Peleus'.lower()\n",
    "    text1 = open(BASE_PATH + 'corpus/iliad.mb.txt', encoding='utf-8').read().lower()\n",
    "    text2 = open(BASE_PATH + 'corpus/odyssey.mb.txt', encoding='utf-8').read().lower()\n",
    "    text = text1 + text2\n",
    "    test_words = ['he', 'she', 'ulysses', 'penelope', 'achaeans', 'trojans']\n",
    "if dataset == 'dickens':\n",
    "    path = BASE_PATH + 'corpus/Dickens/'\n",
    "    text = load_corpus(path)\n",
    "    test_words = ['he', 'she', 'paris', 'london', 'table', 'rare', 'monday', 'sunday', 'man', 'woman', 'king', 'queen', 'boy',\n",
    "                  'girl']\n",
    "elif dataset == 'selma':\n",
    "    path = BASE_PATH + 'corpus/Selma/'\n",
    "    text = load_corpus(path)\n",
    "    test_words = ['han', 'hon', 'att', 'bord', 'bordet', 'måndag', 'söndag', 'man', 'kvinna', 'kung', 'drottning',\n",
    "                  'pojke', 'flicka']\n",
    "elif dataset == 'big':\n",
    "    path = BASE_PATH + 'corpus/Dickens/'\n",
    "    text = load_corpus(path)\n",
    "    path = BASE_PATH + 'corpus/Norvig/'\n",
    "    text += load_corpus(path)\n",
    "    test_words = ['he', 'she', 'paris', 'london', 'table', 'rare', 'monday', 'sunday', 'man', 'woman', 'king', 'queen', 'boy',\n",
    "                  'girl']    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set all the text in lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['book', 'i', 'the', 'quarrel', 'between']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = text.lower()\n",
    "word_seq = re.findall('\\p{L}+', text)\n",
    "word_seq[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can downsample the frequent words. We first count the words, then we discard randomly some words in the text, depending on their frequency. Frequent words will often be discarded. Rare words, never. We will have to count them again after sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272712"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = Counter(word_seq)\n",
    "word_cnt = sum(counts.values())\n",
    "word_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15905, 4746, 110)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts['the'], counts['he'], counts['penelope']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The discard probability threshold, following § 2.3 of the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "discard_probs = dict(counts)\n",
    "for key in discard_probs:\n",
    "    discard_probs[key] = max(0, 1 - math.sqrt(t/(counts[key]/word_cnt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8690560952429589, 0.7602888379452187, 0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discard_probs['the'], discard_probs['he'], discard_probs['penelope']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsampled_word_seq = []\n",
    "for word in word_seq:\n",
    "    if discard_probs[word] < np.random.random():\n",
    "        subsampled_word_seq += [word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOWNSAMPLING:\n",
    "    word_seq = subsampled_word_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272712"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = Counter(word_seq)\n",
    "word_cnt = sum(counts.values())\n",
    "word_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15905, 4746, 110)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts['the'], counts['he'], counts['penelope']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.05832159934289653, 0.01740297456657573, 0.00040335592126492415)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts['the']/word_cnt, counts['he']/word_cnt, counts['penelope']/word_cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract the unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'abantes',\n",
       " 'abarbarea',\n",
       " 'abas',\n",
       " 'abate',\n",
       " 'abated',\n",
       " 'abetting',\n",
       " 'abhorred',\n",
       " 'abians',\n",
       " 'abide']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words = sorted(list(counts.keys()))\n",
    "unique_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9725"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(unique_words)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we create indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {word: i for (i, word) in enumerate(unique_words)}\n",
    "idx2word = {v: k for k, v in word2idx.items()}\n",
    "#word2idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We map the words to their indices and we get the sequence of word indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1037, 4334, 8518, 6666, 897]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "widx_seq = list(map(word2idx.get, word_seq))\n",
    "widx_seq[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply a power tranform to a list of counts and we return power transformed probabilities:\n",
    "$$\n",
    "\\frac{\\text{cnt}(w)^\\text{power}}{\\sum_i \\text{cnt}(w_i)^\\text{power}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_transform(counts, power):\n",
    "    trfmd_probs = dict()\n",
    "    for word in counts:\n",
    "        trfmd_probs[word] = math.pow(counts[word], power)\n",
    "    sum_probs = sum(trfmd_probs.values())\n",
    "    for word in trfmd_probs:\n",
    "        trfmd_probs[word] /= sum_probs\n",
    "    return trfmd_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trfmd_probs = power_transform(counts, power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.020224400021262735, 0.008165282068782646, 0.00048503145644814705)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trfmd_probs['the'], trfmd_probs['he'], trfmd_probs['penelope']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative sampling\n",
    "For each positive pair, and word and a context word, we draw $k$ words randomly to form negative pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build the index and probability lists for the random choice function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trfmd_probs_idx = {word2idx[k]: v for k, v in trfmd_probs.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`random.choices` needs the index and the probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_idx, probs = zip(*trfmd_probs_idx.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the words in the context, we draw $k$ as many words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1863,\n",
       " 2262,\n",
       " 2334,\n",
       " 4661,\n",
       " 9616,\n",
       " 1486,\n",
       " 3213,\n",
       " 2493,\n",
       " 3970,\n",
       " 2313,\n",
       " 1700,\n",
       " 7251,\n",
       " 2313,\n",
       " 4977,\n",
       " 184,\n",
       " 3521,\n",
       " 3200,\n",
       " 9241,\n",
       " 3288,\n",
       " 1054]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(draw_idx, weights=probs, k=K_NEG * 2 * w_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all the words, we form positive and negative pairs. We extract the context words of a word from its neighbors in the word sequence to form the positive pairs and at random to form the negative ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minibatch_generator(widx_seq):\n",
    "    # A batch consists of the positive pairs generated\n",
    "    # by a word and its context and the negative pairs:\n",
    "    # w_size * 2 + K_NEG * w_size * 2 = (K_NEG + 1) * w_size * 2\n",
    "    for idx, widx in tqdm(enumerate(widx_seq[w_size:-w_size], w_size)):\n",
    "        # We create the start and end indices as in range(start, end)\n",
    "        start_idx = idx - w_size\n",
    "        end_idx = idx + w_size + 1\n",
    "        # We create pairs from the left context: start_idx -> idx\n",
    "        # and from the right context idx + 1 -> end_idx\n",
    "        # The input word\n",
    "        X_i = [widx_seq[idx]] * (K_NEG + 1) * 2 * w_size\n",
    "        # The context words\n",
    "        X_c = [widx_seq[c_idx] for c_idx in\n",
    "               [*range(start_idx, idx), *range(idx + 1, end_idx)]]\n",
    "        # The random words to form negative pairs\n",
    "        X_c += random.choices(draw_idx, weights=probs,\n",
    "                              k=K_NEG * 2 * w_size)\n",
    "        y = [1] * w_size * 2 + [0] * w_size * 2 * K_NEG\n",
    "        y = np.array(y)\n",
    "        X_i = np.array(X_i)\n",
    "        X_c = np.array(X_c)\n",
    "        yield X_i, X_c, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now the architecture. We build two inputs: The left input is the input word and the right one is a context word. This corresponds to two kinds of embeddings input and context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1, 100)       972500      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 100)       972500      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 1, 1)         0           embedding[0][0]                  \n",
      "                                                                 embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1, 1)         2           dot[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 1,945,002\n",
      "Trainable params: 1,945,002\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "i_word = Input(shape=(1,))\n",
    "i_embedding = Embedding(vocab_size,\n",
    "                        embedding_dim,\n",
    "                        input_length=1)(i_word)\n",
    "\n",
    "c_word = Input(shape=(1,))\n",
    "c_embedding = Embedding(vocab_size,\n",
    "                        embedding_dim,\n",
    "                        input_length=1)(c_word)\n",
    "\n",
    "dot_prod = Dot(axes=-1)([i_embedding, c_embedding])  # normalize=True\n",
    "output = Dense(1, activation='sigmoid')(dot_prod)\n",
    "model = Model([i_word, c_word], output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Loss\n",
    "As defined in § 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_neg(y_true, y_hat):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    log_y_hat_1 = tf.math.log(y_hat) \n",
    "    log_y_hat_0 = tf.math.log(1.0 - y_hat)\n",
    "    loss = tf.math.add(tf.math.multiply(y_true, log_y_hat_1),\n",
    "                       tf.math.multiply(1.0 - y_true, log_y_hat_0))\n",
    "    loss = -tf.reduce_sum(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=loss_neg, optimizer='rmsprop')#, run_eagerly=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function to measure the vector similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_sim_vecs(vector, U, nbr_words=10):\n",
    "    # Here cosine distance and not cosine\n",
    "    # distance between equal vectors: 0. max distance: 2\n",
    "    dist = [cosine(vector, U[i, :]) if np.any(U[i, :]) else 2\n",
    "            for i in range(U.shape[0])]\n",
    "    sorted_vectors = sorted(range(len(dist)), key=lambda k: dist[k])\n",
    "    return sorted_vectors[1:nbr_words + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "272708it [35:38, 127.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 9.868846893310547\n",
      "he ['she', 'we', 'they', 'recognise', 'minerva', 'plied', 'sports', 'it', 'pleases', 'i']\n",
      "she ['minerva', 'he', 'juno', 'penelope', 'seemly', 'ulysses', 'they', 'euryclea', 'piloted', 'hector']\n",
      "ulysses ['telemachus', 'eumaeus', 'antinous', 'penelope', 'mercury', 'minerva', 'euryclea', 'began', 'him', 'king']\n",
      "penelope ['telemachus', 'dear', 'neptune', 'father', 'hector', 'ulysses', 'menelaus', 'eumaeus', 'apollo', 'juno']\n",
      "achaeans ['gods', 'suitors', 'trojans', 'danaans', 'others', 'immortals', 'phaeacians', 'argives', 'myrmidons', 'we']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:00, 132.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trojans ['achaeans', 'suitors', 'danaans', 'others', 'argives', 'other', 'plain', 'sea', 'themselves', 'earth']\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "272708it [34:26, 132.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 9.982368469238281\n",
      "he ['she', 'they', 'overtook', 'ulysses', 'lowing', 'minerva', 'heinous', 'flits', 'dispersed', 'breaking']\n",
      "she ['he', 'they', 'minerva', 'steps', 'penelope', 'seemly', 'mercury', 'juno', 'piloted', 'athlete']\n",
      "ulysses ['telemachus', 'eumaeus', 'penelope', 'antinous', 'mercury', 'euryclea', 'menelaus', 'minerva', 'straightening', 'idomeneus']\n",
      "penelope ['telemachus', 'eumaeus', 'nurse', 'euryclea', 'neptune', 'antinous', 'dear', 'menelaus', 'juno', 'father']\n",
      "achaeans ['trojans', 'suitors', 'danaans', 'others', 'gods', 'argives', 'sun', 'fight', 'phaeacians', 'sea']\n",
      "trojans ['achaeans', 'suitors', 'danaans', 'argives', 'others', 'sea', 'themselves', 'gods', 'earth', 'fight']\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    print(\"Epoch {}/{}\".format(epoch + 1, EPOCHS))\n",
    "    for i, batch in enumerate(minibatch_generator(widx_seq)):\n",
    "        X_i, X_c, y = batch\n",
    "        loss = model.train_on_batch([X_i, X_c], y)\n",
    "    print('Loss:', loss)\n",
    "    embeddings = model.get_weights()[0]\n",
    "    most_sim_words = {}\n",
    "    for w in test_words:\n",
    "        most_sim_words[w] = most_sim_vecs(embeddings[word2idx[w]], embeddings)\n",
    "        most_sim_words[w] = list(map(idx2word.get, most_sim_words[w]))\n",
    "        print(w, most_sim_words[w])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nneg_loss and 2 epochs POW = 0.75. No downsampling (2021/04/08)\\nLoss: 10.052577018737793\\nhe ['they', 'she', 'we', 'it', 'seemed', 'pool', 'had', 'minerva', 'wave', 'foursquare']\\nshe ['minerva', 'venus', 'penelope', 'juno', 'he', 'telemachus', 'they', 'loathed', 'helen', 'we']\\nulysses ['telemachus', 'penelope', 'antinous', 'eumaeus', 'euryclea', 'menelaus', 'eurymachus', 'idomeneus', 'apollo', 'noemon']\\npenelope ['antinous', 'telemachus', 'eumaeus', 'dear', 'euryclea', 'eurymachus', 'juno', 'nurse', 'menelaus', 'minerva']\\nachaeans ['trojans', 'danaans', 'gods', 'others', 'argives', 'suitors', 'ships', 'sea', 'men', 'phaeacians']\\ntrojans ['achaeans', 'argives', 'danaans', 'gods', 'others', 'other', 'plain', 'sea', 'ships', 'fighting']\\n\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "neg_loss and 2 epochs POW = 0.75. No downsampling (2021/04/08)\n",
    "Loss: 10.052577018737793\n",
    "he ['they', 'she', 'we', 'it', 'seemed', 'pool', 'had', 'minerva', 'wave', 'foursquare']\n",
    "she ['minerva', 'venus', 'penelope', 'juno', 'he', 'telemachus', 'they', 'loathed', 'helen', 'we']\n",
    "ulysses ['telemachus', 'penelope', 'antinous', 'eumaeus', 'euryclea', 'menelaus', 'eurymachus', 'idomeneus', 'apollo', 'noemon']\n",
    "penelope ['antinous', 'telemachus', 'eumaeus', 'dear', 'euryclea', 'eurymachus', 'juno', 'nurse', 'menelaus', 'minerva']\n",
    "achaeans ['trojans', 'danaans', 'gods', 'others', 'argives', 'suitors', 'ships', 'sea', 'men', 'phaeacians']\n",
    "trojans ['achaeans', 'argives', 'danaans', 'gods', 'others', 'other', 'plain', 'sea', 'ships', 'fighting']\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Loss: 9.982368469238281\n",
    "neg_loss and 2 epochs POW = 0.75. No downsampling (2021/04/09)\n",
    "he ['she', 'they', 'overtook', 'ulysses', 'lowing', 'minerva', 'heinous', 'flits', 'dispersed', 'breaking']\n",
    "she ['he', 'they', 'minerva', 'steps', 'penelope', 'seemly', 'mercury', 'juno', 'piloted', 'athlete']\n",
    "ulysses ['telemachus', 'eumaeus', 'penelope', 'antinous', 'mercury', 'euryclea', 'menelaus', 'minerva', 'straightening', 'idomeneus']\n",
    "penelope ['telemachus', 'eumaeus', 'nurse', 'euryclea', 'neptune', 'antinous', 'dear', 'menelaus', 'juno', 'father']\n",
    "achaeans ['trojans', 'suitors', 'danaans', 'others', 'gods', 'argives', 'sun', 'fight', 'phaeacians', 'sea']\n",
    "trojans ['achaeans', 'suitors', 'danaans', 'argives', 'others', 'sea', 'themselves', 'gods', 'earth', 'fight']\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nneg_loss and 2 epochs POW = 0.75. No downsampling (2021/04/08), dot normalized\\nLoss: 9.279374122619629\\nhe ['she', 'they', 'i', 'minerva', 'achilles', 'glad', 'behind', 'iris', 'scylla', 'rude']\\nshe ['he', 'minerva', 'they', 'iris', 'apollo', 'telemachus', 'eueneus', 'juno', 'euryclea', 'scylla']\\nulysses ['telemachus', 'alcinous', 'antinous', 'king', 'agamemnon', 'ajax', 'achilles', 'minerva', 'apollo', 'eumaeus']\\npenelope ['dear', 'father', 'nurse', 'said', 'antinous', 'agamemnon', 'telemachus', 'eumaeus', 'sir', 'wife']\\nachaeans ['danaans', 'trojans', 'argives', 'others', 'suitors', 'gods', 'immortals', 'phaeacians', 'blessed', 'other']\\ntrojans ['achaeans', 'danaans', 'argives', 'phaeacians', 'sun', 'immortals', 'sea', 'gods', 'suitors', 'plain']\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "neg_loss and 2 epochs POW = 0.75. No downsampling (2021/04/08), dot normalized\n",
    "Loss: 9.279374122619629\n",
    "he ['she', 'they', 'i', 'minerva', 'achilles', 'glad', 'behind', 'iris', 'scylla', 'rude']\n",
    "she ['he', 'minerva', 'they', 'iris', 'apollo', 'telemachus', 'eueneus', 'juno', 'euryclea', 'scylla']\n",
    "ulysses ['telemachus', 'alcinous', 'antinous', 'king', 'agamemnon', 'ajax', 'achilles', 'minerva', 'apollo', 'eumaeus']\n",
    "penelope ['dear', 'father', 'nurse', 'said', 'antinous', 'agamemnon', 'telemachus', 'eumaeus', 'sir', 'wife']\n",
    "achaeans ['danaans', 'trojans', 'argives', 'others', 'suitors', 'gods', 'immortals', 'phaeacians', 'blessed', 'other']\n",
    "trojans ['achaeans', 'danaans', 'argives', 'phaeacians', 'sun', 'immortals', 'sea', 'gods', 'suitors', 'plain']\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nneg_loss and 2 epochs POW = 1. No downsampling (2021/04/08)\\nLoss: 10.320120811462402\\nhe ['she', 'they', 'grip', 'wielder', 'pursuing', 'augur', 'i', 'enchantress', 'we', 'it']\\nshe ['minerva', 'he', 'juno', 'penelope', 'they', 'telemachus', 'theoclymenus', 'i', 'eumaeus', 'agreeable']\\nulysses ['telemachus', 'achilles', 'nestor', 'penelope', 'agamemnon', 'antinous', 'apollo', 'menelaus', 'neptune', 'eurymachus']\\npenelope ['telemachus', 'eumaeus', 'apollo', 'nurse', 'juno', 'neptune', 'antinous', 'ulysses', 'minerva', 'circe']\\nachaeans ['trojans', 'danaans', 'gods', 'others', 'argives', 'we', 'suitors', 'phaeacians', 'reserve', 'sun']\\ntrojans ['achaeans', 'argives', 'danaans', 'suitors', 'myrmidons', 'gods', 'troy', 'phaeacians', 'sea', 'sighed']\\n\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "neg_loss and 2 epochs POW = 1. No downsampling (2021/04/08)\n",
    "Loss: 10.320120811462402\n",
    "he ['she', 'they', 'grip', 'wielder', 'pursuing', 'augur', 'i', 'enchantress', 'we', 'it']\n",
    "she ['minerva', 'he', 'juno', 'penelope', 'they', 'telemachus', 'theoclymenus', 'i', 'eumaeus', 'agreeable']\n",
    "ulysses ['telemachus', 'achilles', 'nestor', 'penelope', 'agamemnon', 'antinous', 'apollo', 'menelaus', 'neptune', 'eurymachus']\n",
    "penelope ['telemachus', 'eumaeus', 'apollo', 'nurse', 'juno', 'neptune', 'antinous', 'ulysses', 'minerva', 'circe']\n",
    "achaeans ['trojans', 'danaans', 'gods', 'others', 'argives', 'we', 'suitors', 'phaeacians', 'reserve', 'sun']\n",
    "trojans ['achaeans', 'argives', 'danaans', 'suitors', 'myrmidons', 'gods', 'troy', 'phaeacians', 'sea', 'sighed']\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nneg_loss and 4 epochs POW = 0.75?\\nhe ['she', 'they', 'achilles', 'i', 'bride', 'halt', 'ruined', 'mars', 'solitary', 'muttering']\\nshe ['minerva', 'he', 'they', 'handmaids', 'helen', 'heaven', 'maids', 'venus', 'wand', 'steps']\\nulysses ['telemachus', 'eumaeus', 'aegisthus', 'alcinous', 'antinous', 'mercury', 'penelope', 'menelaus', 'nestor', 'eurymachus']\\npenelope ['antinous', 'eumaeus', 'telemachus', 'nurse', 'dear', 'alcinous', 'piteously', 'euryclea', 'mercury', 'leto']\\nachaeans ['danaans', 'trojans', 'argives', 'gods', 'others', 'suitors', 'phaeacians', 'sea', 'alone', 'closely']\\ntrojans ['achaeans', 'argives', 'danaans', 'gods', 'others', 'sea', 'earth', 'hindered', 'themselves', 'suitors']\\n\\nLoss: 9.882923126220703 POW = 1\\nhe ['she', 'they', 'key', 'i', 'we', 'destroys', 'achilles', 'glares', 'dearest', 'mercury']\\nshe ['he', 'minerva', 'they', 'penelope', 'melanthius', 'apollo', 'mercury', 'i', 'telemachus', 'alcyone']\\nulysses ['telemachus', 'antinous', 'achilles', 'penelope', 'agamemnon', 'eumaeus', 'minerva', 'piteously', 'euryclea', 'ajax']\\npenelope ['telemachus', 'nurse', 'antinous', 'eumaeus', 'euryclea', 'juno', 'dear', 'apollo', 'thetis', 'menelaus']\\nachaeans ['trojans', 'danaans', 'argives', 'others', 'suitors', 'gods', 'phaeacians', 'myrmidons', 'immortals', 'lycians']\\ntrojans ['achaeans', 'argives', 'danaans', 'others', 'suitors', 'gods', 'lycians', 'myrmidons', 'themselves', 'driven']\\n\\nLoss: 9.43042278289795 POW = 1\\nhe ['they', 'she', 'healed', 'dagger', 'i', 'prisoner', 'we', 'apollo', 'horsehair', 'craftiest']\\nshe ['minerva', 'he', 'juno', 'they', 'venus', 'courtesy', 'maids', 'veil', 'penelope', 'iris']\\nulysses ['telemachus', 'agamemnon', 'achilles', 'eumaeus', 'neptune', 'nestor', 'menelaus', 'alcinous', 'idomeneus', 'penelope']\\npenelope ['eumaeus', 'nurse', 'antinous', 'telemachus', 'euryclea', 'juno', 'neptune', 'alcinous', 'eurymachus', 'mother']\\nachaeans ['trojans', 'argives', 'danaans', 'suitors', 'gods', 'others', 'phaeacians', 'themselves', 'fall', 'nothing']\\ntrojans ['achaeans', 'argives', 'danaans', 'dogs', 'themselves', 'others', 'suitors', 'fall', 'sooner', 'gods']\\n\\nLoss: 11.508221626281738 POW = 0.75\\nhe ['they', 'she', 'offal', 'gorgon', 'place', 'undisturbed', 'prizes', 'hind', 'seat', 'steaks']\\nshe ['minerva', 'juno', 'vixen', 'arete', 'heron', 'he', 'they', 'beguiled', 'venus', 'moody']\\nulysses ['mercury', 'telemachus', 'penelope', 'antinous', 'leto', 'alcinous', 'swineherd', 'idomeneus', 'eumaeus', 'diomed']\\npenelope ['euryclea', 'eumaeus', 'antinous', 'nurse', 'leto', 'alcinous', 'mentor', 'telemachus', 'dear', 'juno']\\nachaeans ['argives', 'trojans', 'danaans', 'gods', 'suitors', 'others', 'ships', 'fighting', 'day', 'battle']\\ntrojans ['achaeans', 'argives', 'danaans', 'ships', 'themselves', 'lycians', 'ground', 'sea', 'heroes', 'dogs']\\nLoss: 9.757258415222168 POW = 0.75\\nhe ['they', 'she', 'it', 'dipping', 'targets', 'journey', 'devil', 'sunium', 'safely', 'democoon']\\nshe ['they', 'he', 'minerva', 'simple', 'juno', 'maids', 'slipped', 'calypso', 'husband', 'overboard']\\nulysses ['penelope', 'telemachus', 'antinous', 'menelaus', 'glad', 'alcinous', 'eumaeus', 'euryclea', 'eurymachus', 'nestor']\\npenelope ['telemachus', 'antinous', 'eumaeus', 'alcinous', 'nurse', 'euryclea', 'ulysses', 'thetis', 'mercury', 'dear']\\nachaeans ['danaans', 'trojans', 'argives', 'suitors', 'gods', 'others', 'immortals', 'sea', 'ships', 'myrmidons']\\ntrojans ['achaeans', 'danaans', 'argives', 'ships', 'suitors', 'earth', 'fighting', 'sea', 'themselves', 'immortals']\\n\\nLoss: 7.38845682144165 POW = 0.75 dot norm\\nhe ['she', 'they', 'minerva', 'scoundrel', 'i', 'achilles', 'we', 'apollo', 'ineffable', 'exposed']\\nshe ['he', 'minerva', 'juno', 'sun', 'they', 'phemius', 'venus', 'euryalus', 'penelope', 'apollo']\\nulysses ['achilles', 'telemachus', 'antinous', 'diomed', 'swineherd', 'antilochus', 'penelope', 'agamemnon', 'hector', 'menelaus']\\npenelope ['euryclea', 'telemachus', 'dear', 'nurse', 'alcinous', 'answered', 'said', 'queen', 'o', 'eumaeus']\\nachaeans ['trojans', 'danaans', 'argives', 'gods', 'suitors', 'others', 'immortals', 'sun', 'phaeacians', 'lycians']\\ntrojans ['achaeans', 'danaans', 'argives', 'others', 'lycians', 'dogs', 'suitors', 'immortals', 'gods', 'main']\\n\\nLoss: 9.18224811553955 POW = 0.75 dot norm\\nhe ['she', 'they', 'i', 'aim', 'penelope', 'glad', 'antinous', 'minerva', 'sun', 'adrestus']\\nshe ['he', 'minerva', 'juno', 'sarpedon', 'sun', 'they', 'venus', 'antinous', 'obeyed', 'maids']\\nulysses ['antinous', 'swineherd', 'ajax', 'menelaus', 'diomed', 'eurymachus', 'agamemnon', 'alcinous', 'eumaeus', 'achilles']\\npenelope ['dear', 'father', 'eumaeus', 'telemachus', 'euryclea', 'nurse', 'piteously', 'mother', 'neighbour', 'antinous']\\nachaeans ['danaans', 'trojans', 'gods', 'argives', 'others', 'phaeacians', 'immortals', 'suitors', 'we', 'birds']\\ntrojans ['achaeans', 'argives', 'danaans', 'suitors', 'phaeacians', 'themselves', 'lycians', 'immortals', 'myrmidons', 'gods']\\n\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "neg_loss and 4 epochs POW = 0.75?\n",
    "he ['she', 'they', 'achilles', 'i', 'bride', 'halt', 'ruined', 'mars', 'solitary', 'muttering']\n",
    "she ['minerva', 'he', 'they', 'handmaids', 'helen', 'heaven', 'maids', 'venus', 'wand', 'steps']\n",
    "ulysses ['telemachus', 'eumaeus', 'aegisthus', 'alcinous', 'antinous', 'mercury', 'penelope', 'menelaus', 'nestor', 'eurymachus']\n",
    "penelope ['antinous', 'eumaeus', 'telemachus', 'nurse', 'dear', 'alcinous', 'piteously', 'euryclea', 'mercury', 'leto']\n",
    "achaeans ['danaans', 'trojans', 'argives', 'gods', 'others', 'suitors', 'phaeacians', 'sea', 'alone', 'closely']\n",
    "trojans ['achaeans', 'argives', 'danaans', 'gods', 'others', 'sea', 'earth', 'hindered', 'themselves', 'suitors']\n",
    "\n",
    "Loss: 9.882923126220703 POW = 1\n",
    "he ['she', 'they', 'key', 'i', 'we', 'destroys', 'achilles', 'glares', 'dearest', 'mercury']\n",
    "she ['he', 'minerva', 'they', 'penelope', 'melanthius', 'apollo', 'mercury', 'i', 'telemachus', 'alcyone']\n",
    "ulysses ['telemachus', 'antinous', 'achilles', 'penelope', 'agamemnon', 'eumaeus', 'minerva', 'piteously', 'euryclea', 'ajax']\n",
    "penelope ['telemachus', 'nurse', 'antinous', 'eumaeus', 'euryclea', 'juno', 'dear', 'apollo', 'thetis', 'menelaus']\n",
    "achaeans ['trojans', 'danaans', 'argives', 'others', 'suitors', 'gods', 'phaeacians', 'myrmidons', 'immortals', 'lycians']\n",
    "trojans ['achaeans', 'argives', 'danaans', 'others', 'suitors', 'gods', 'lycians', 'myrmidons', 'themselves', 'driven']\n",
    "\n",
    "Loss: 9.43042278289795 POW = 1\n",
    "he ['they', 'she', 'healed', 'dagger', 'i', 'prisoner', 'we', 'apollo', 'horsehair', 'craftiest']\n",
    "she ['minerva', 'he', 'juno', 'they', 'venus', 'courtesy', 'maids', 'veil', 'penelope', 'iris']\n",
    "ulysses ['telemachus', 'agamemnon', 'achilles', 'eumaeus', 'neptune', 'nestor', 'menelaus', 'alcinous', 'idomeneus', 'penelope']\n",
    "penelope ['eumaeus', 'nurse', 'antinous', 'telemachus', 'euryclea', 'juno', 'neptune', 'alcinous', 'eurymachus', 'mother']\n",
    "achaeans ['trojans', 'argives', 'danaans', 'suitors', 'gods', 'others', 'phaeacians', 'themselves', 'fall', 'nothing']\n",
    "trojans ['achaeans', 'argives', 'danaans', 'dogs', 'themselves', 'others', 'suitors', 'fall', 'sooner', 'gods']\n",
    "\n",
    "Loss: 11.508221626281738 POW = 0.75\n",
    "he ['they', 'she', 'offal', 'gorgon', 'place', 'undisturbed', 'prizes', 'hind', 'seat', 'steaks']\n",
    "she ['minerva', 'juno', 'vixen', 'arete', 'heron', 'he', 'they', 'beguiled', 'venus', 'moody']\n",
    "ulysses ['mercury', 'telemachus', 'penelope', 'antinous', 'leto', 'alcinous', 'swineherd', 'idomeneus', 'eumaeus', 'diomed']\n",
    "penelope ['euryclea', 'eumaeus', 'antinous', 'nurse', 'leto', 'alcinous', 'mentor', 'telemachus', 'dear', 'juno']\n",
    "achaeans ['argives', 'trojans', 'danaans', 'gods', 'suitors', 'others', 'ships', 'fighting', 'day', 'battle']\n",
    "trojans ['achaeans', 'argives', 'danaans', 'ships', 'themselves', 'lycians', 'ground', 'sea', 'heroes', 'dogs']\n",
    "Loss: 9.757258415222168 POW = 0.75\n",
    "he ['they', 'she', 'it', 'dipping', 'targets', 'journey', 'devil', 'sunium', 'safely', 'democoon']\n",
    "she ['they', 'he', 'minerva', 'simple', 'juno', 'maids', 'slipped', 'calypso', 'husband', 'overboard']\n",
    "ulysses ['penelope', 'telemachus', 'antinous', 'menelaus', 'glad', 'alcinous', 'eumaeus', 'euryclea', 'eurymachus', 'nestor']\n",
    "penelope ['telemachus', 'antinous', 'eumaeus', 'alcinous', 'nurse', 'euryclea', 'ulysses', 'thetis', 'mercury', 'dear']\n",
    "achaeans ['danaans', 'trojans', 'argives', 'suitors', 'gods', 'others', 'immortals', 'sea', 'ships', 'myrmidons']\n",
    "trojans ['achaeans', 'danaans', 'argives', 'ships', 'suitors', 'earth', 'fighting', 'sea', 'themselves', 'immortals']\n",
    "\n",
    "Loss: 7.38845682144165 POW = 0.75 dot norm\n",
    "he ['she', 'they', 'minerva', 'scoundrel', 'i', 'achilles', 'we', 'apollo', 'ineffable', 'exposed']\n",
    "she ['he', 'minerva', 'juno', 'sun', 'they', 'phemius', 'venus', 'euryalus', 'penelope', 'apollo']\n",
    "ulysses ['achilles', 'telemachus', 'antinous', 'diomed', 'swineherd', 'antilochus', 'penelope', 'agamemnon', 'hector', 'menelaus']\n",
    "penelope ['euryclea', 'telemachus', 'dear', 'nurse', 'alcinous', 'answered', 'said', 'queen', 'o', 'eumaeus']\n",
    "achaeans ['trojans', 'danaans', 'argives', 'gods', 'suitors', 'others', 'immortals', 'sun', 'phaeacians', 'lycians']\n",
    "trojans ['achaeans', 'danaans', 'argives', 'others', 'lycians', 'dogs', 'suitors', 'immortals', 'gods', 'main']\n",
    "\n",
    "Loss: 9.18224811553955 POW = 0.75 dot norm\n",
    "he ['she', 'they', 'i', 'aim', 'penelope', 'glad', 'antinous', 'minerva', 'sun', 'adrestus']\n",
    "she ['he', 'minerva', 'juno', 'sarpedon', 'sun', 'they', 'venus', 'antinous', 'obeyed', 'maids']\n",
    "ulysses ['antinous', 'swineherd', 'ajax', 'menelaus', 'diomed', 'eurymachus', 'agamemnon', 'alcinous', 'eumaeus', 'achilles']\n",
    "penelope ['dear', 'father', 'eumaeus', 'telemachus', 'euryclea', 'nurse', 'piteously', 'mother', 'neighbour', 'antinous']\n",
    "achaeans ['danaans', 'trojans', 'gods', 'argives', 'others', 'phaeacians', 'immortals', 'suitors', 'we', 'birds']\n",
    "trojans ['achaeans', 'argives', 'danaans', 'suitors', 'phaeacians', 'themselves', 'lycians', 'immortals', 'myrmidons', 'gods']\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "neg_loss and 4 epochs, downsampling\n",
    "Loss: 9.66569995880127\n",
    "he ['cunningly', 'nigh', 'quick', 'trachis', 'despairingly', 'lesson', 'withdrew', 'she', 'keenly', 'bewail']\n",
    "she ['attempt', 'overtakes', 'aloud', 'piloted', 'gush', 'hawk', 'he', 'nausicaa', 'meliboea', 'thrash']\n",
    "ulysses ['swineherd', 'tried', 'indisputable', 'happen', 'invincible', 'arrive', 'accompanied', 'stains', 'cyclopes', 'rouse']\n",
    "penelope ['nurse', 'desire', 'telemachus', 'madam', 'stockman', 'angrily', 'reminds', 'eurynome', 'troubled', 'alas']\n",
    "achaeans ['danaans', 'argives', 'oracles', 'faint', 'pick', 'avail', 'knowledge', 'useful', 'people', 'unharnessed']\n",
    "trojans ['wander', 'perilous', 'erembians', 'maniac', 'evils', 'undaunted', 'argives', 'thwart', 'violate', 'warding']\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nLoss: 0.3799111843109131\\ncross entropy, 4 epochs\\nhe ['she', 'permitted', 'they', 'maris', 'accustomed', 'swooping', 'curiously', 'abydos', 'kneading', 'eilesium']\\nshe ['minerva', 'they', 'juno', 'he', 'her', 'venus', 'empty', 'iris', 'husband', 'permitted']\\nulysses ['penelope', 'telemachus', 'alcinous', 'eurymachus', 'eumaeus', 'antinous', 'mercury', 'leto', 'nausicaa', 'euryclea']\\npenelope ['eumaeus', 'euryclea', 'telemachus', 'antinous', 'dear', 'nausicaa', 'alcinous', 'nurse', 'eurymachus', 'ulysses']\\nachaeans ['trojans', 'danaans', 'others', 'argives', 'gods', 'sea', 'ships', 'suitors', 'forever', 'yourselves']\\ntrojans ['achaeans', 'argives', 'danaans', 'ground', 'others', 'gods', 'sea', 'suitors', 'ships', 'earth']\\n\\nLoss: 0.42960622906684875\\nhe ['she', 'they', 'cooling', 'we', 'wain', 'i', 'pretty', 'morn', 'reeds', 'scream']\\nshe ['he', 'minerva', 'they', 'achilles', 'calypso', 'iris', 'euryclea', 'thersites', 'mercury', 'maids']\\nulysses ['telemachus', 'antinous', 'agamemnon', 'achilles', 'alcinous', 'penelope', 'menelaus', 'nestor', 'euryclea', 'eumaeus']\\npenelope ['telemachus', 'eumaeus', 'nurse', 'euryclea', 'dear', 'antinous', 'juno', 'alcinous', 'menelaus', 'sir']\\nachaeans ['argives', 'danaans', 'trojans', 'others', 'suitors', 'sun', 'gods', 'immortals', 'phaeacians', 'lycians']\\ntrojans ['achaeans', 'argives', 'danaans', 'plain', 'themselves', 'break', 'grow', 'suitors', 'ships', 'mountains']\\n\\n\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Loss: 0.3799111843109131\n",
    "cross entropy, 4 epochs\n",
    "he ['she', 'permitted', 'they', 'maris', 'accustomed', 'swooping', 'curiously', 'abydos', 'kneading', 'eilesium']\n",
    "she ['minerva', 'they', 'juno', 'he', 'her', 'venus', 'empty', 'iris', 'husband', 'permitted']\n",
    "ulysses ['penelope', 'telemachus', 'alcinous', 'eurymachus', 'eumaeus', 'antinous', 'mercury', 'leto', 'nausicaa', 'euryclea']\n",
    "penelope ['eumaeus', 'euryclea', 'telemachus', 'antinous', 'dear', 'nausicaa', 'alcinous', 'nurse', 'eurymachus', 'ulysses']\n",
    "achaeans ['trojans', 'danaans', 'others', 'argives', 'gods', 'sea', 'ships', 'suitors', 'forever', 'yourselves']\n",
    "trojans ['achaeans', 'argives', 'danaans', 'ground', 'others', 'gods', 'sea', 'suitors', 'ships', 'earth']\n",
    "\n",
    "Loss: 0.42960622906684875\n",
    "he ['she', 'they', 'cooling', 'we', 'wain', 'i', 'pretty', 'morn', 'reeds', 'scream']\n",
    "she ['he', 'minerva', 'they', 'achilles', 'calypso', 'iris', 'euryclea', 'thersites', 'mercury', 'maids']\n",
    "ulysses ['telemachus', 'antinous', 'agamemnon', 'achilles', 'alcinous', 'penelope', 'menelaus', 'nestor', 'euryclea', 'eumaeus']\n",
    "penelope ['telemachus', 'eumaeus', 'nurse', 'euryclea', 'dear', 'antinous', 'juno', 'alcinous', 'menelaus', 'sir']\n",
    "achaeans ['argives', 'danaans', 'trojans', 'others', 'suitors', 'sun', 'gods', 'immortals', 'phaeacians', 'lycians']\n",
    "trojans ['achaeans', 'argives', 'danaans', 'plain', 'themselves', 'break', 'grow', 'suitors', 'ships', 'mountains']\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dickens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nneg_loss and 3 epochs\\nhe ['she', 'corrections', 'quainter', 'tortuously', 'they', 'disgusts', 'legislature', 'decorously', 'applicants', 'topple']\\nshe ['he', 'florence', 'they', 'wastin', 'underhanded', 'everybody', 'powerfully', 'estella', 'bella', 'nobody']\\nparis ['france', 'england', 'requisition', 'despair', 'italy', 'amazement', 'parliament', 'dust', 'convulsions', 'lincolnshire']\\nlondon ['england', 'town', 'italy', 'france', 'vain', 'paris', 'lincolnshire', 'buckingham', 'itself', 'due']\\ntable ['window', 'fire', 'ground', 'wall', 'floor', 'sofa', 'box', 'road', 'carriage', 'desk']\\nrare ['female', 'singular', 'monstrous', 'special', 'mere', 'moral', 'terrible', 'genteel', 'common', 'remarkable']\\nmonday ['wednesday', 'horseback', 'floor', 'thursday', 'board', 'tiptoe', 'sides', 'entering', 'saturday', 'sunday']\\nsunday ['saturday', 'summer', 'post', 'coffee', 'board', 'stone', 'monday', 'wall', 'green', 'garden']\\nman ['gentleman', 'woman', 'lady', 'person', 'boy', 'child', 'girl', 'dog', 'fellow', 'creature']\\nwoman ['lady', 'girl', 'gentleman', 'creature', 'man', 'fellow', 'person', 'boy', 'child', 'servant']\\nking ['clergyman', 'maker', 'baker', 'cook', 'pawnbroker', 'chandler', 'attorney', 'bride', 'knights', 'mayor']\\naqueen ['forest', 'tumult', 'pile', 'roast', 'professor', 'soot', 'combination', 'mixture', 'bunch', 'depression']\\nboy ['girl', 'child', 'lady', 'servant', 'woman', 'gentleman', 'doctor', 'baby', 'house', 'fellow']\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "neg_loss and 3 epochs\n",
    "he ['she', 'corrections', 'quainter', 'tortuously', 'they', 'disgusts', 'legislature', 'decorously', 'applicants', 'topple']\n",
    "she ['he', 'florence', 'they', 'wastin', 'underhanded', 'everybody', 'powerfully', 'estella', 'bella', 'nobody']\n",
    "paris ['france', 'england', 'requisition', 'despair', 'italy', 'amazement', 'parliament', 'dust', 'convulsions', 'lincolnshire']\n",
    "london ['england', 'town', 'italy', 'france', 'vain', 'paris', 'lincolnshire', 'buckingham', 'itself', 'due']\n",
    "table ['window', 'fire', 'ground', 'wall', 'floor', 'sofa', 'box', 'road', 'carriage', 'desk']\n",
    "rare ['female', 'singular', 'monstrous', 'special', 'mere', 'moral', 'terrible', 'genteel', 'common', 'remarkable']\n",
    "monday ['wednesday', 'horseback', 'floor', 'thursday', 'board', 'tiptoe', 'sides', 'entering', 'saturday', 'sunday']\n",
    "sunday ['saturday', 'summer', 'post', 'coffee', 'board', 'stone', 'monday', 'wall', 'green', 'garden']\n",
    "man ['gentleman', 'woman', 'lady', 'person', 'boy', 'child', 'girl', 'dog', 'fellow', 'creature']\n",
    "woman ['lady', 'girl', 'gentleman', 'creature', 'man', 'fellow', 'person', 'boy', 'child', 'servant']\n",
    "king ['clergyman', 'maker', 'baker', 'cook', 'pawnbroker', 'chandler', 'attorney', 'bride', 'knights', 'mayor']\n",
    "aqueen ['forest', 'tumult', 'pile', 'roast', 'professor', 'soot', 'combination', 'mixture', 'bunch', 'depression']\n",
    "boy ['girl', 'child', 'lady', 'servant', 'woman', 'gentleman', 'doctor', 'baby', 'house', 'fellow']\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\nLoss: 10.337905883789062 POW = 0.75 dot norm 2 epochs\\nhe ['she', 'they', 'i', 'we', 'nicholas', 'everybody', 'nobody', 'it', 'newman', 'agglomeration']\\nshe ['he', 'they', 'i', 'barbara', 'we', 'nicholas', 'everybody', 'fanny', 'husband', 'kate']\\nparis ['london', 'gallery', 'centre', 'stationed', 'park', 'capitol', 'village', 'kitchen', 'execution', 'refreshments']\\nlondon ['kitchen', 'street', 'town', 'city', 'england', 'front', 'market', 'church', 'hall', 'west']\\ntable ['sofa', 'floor', 'desk', 'window', 'fire', 'wall', 'staircase', 'ground', 'fender', 'road']\\nrare ['remarkable', 'serious', 'taste', 'genteel', 'romantic', 'ingenious', 'gentlemanly', 'considerable', 'deal', 'alarming']\\nmonday ['saturday', 'sunday', 'dinner', 'next', 'cathedral', 'morrow', 'floor', 'gazing', 'nine', 'previous']\\nsunday ['saturday', 'summer', 'day', 'cathedral', 'monday', 'week', 'neighbouring', 'stage', 'stone', 'clock']\\nman ['gentleman', 'woman', 'lady', 'person', 'girl', 'fellow', 'boy', 'young', 'devil', 'creature']\\nwoman ['man', 'lady', 'gentleman', 'girl', 'creature', 'fellow', 'young', 'boy', 'person', 'widow']\\nking ['st', 'doctor', 'ghost', 'queen', 'schoolmaster', 'sol', 'bench', 'saracen', 'pastry', 'master']\\nqueen ['king', 'clergyman', 'landlady', 'bunch', 'mixture', 'labyrinth', 'mace', 'masterly', 'species', 'perpetual']\\nboy ['child', 'girl', 'fellow', 'lad', 'woman', 'gentleman', 'man', 'creature', 'lady', 'prisoner']\\ngirl ['boy', 'fellow', 'child', 'woman', 'creature', 'lady', 'man', 'gentleman', 'lad', 'poor']\\n\\nEpoch 2/2\\n\\n3355452it [18:54:19, 49.30it/s]\\n\\nLoss: 10.741490364074707 POW = 0.75 dot no norm 2 epochs\\nhe ['she', 'they', 'unwarrantably', 'gilliflower', 'administer', 'gaieties', 'graymarsh', 'phil', 'ceases', 'aloof']\\nshe ['he', 'they', 'florence', 'everybody', 'thieve', 'edith', 'circumlocutions', 'we', 'honored', 'nobody']\\nparis ['france', 'despair', 'requisition', 'fleet', 'england', 'dart', 'custody', 'parliament', 'succession', 'bevis']\\nlondon ['england', 'town', 'our', 'itself', 'vain', 'paris', 'france', 'lincolnshire', 'italy', 'due']\\ntable ['ground', 'window', 'floor', 'fire', 'wall', 'road', 'board', 'sofa', 'staircase', 'box']\\nrare ['mighty', 'moral', 'extensive', 'singular', 'brief', 'special', 'lively', 'female', 'mere', 'trifling']\\nmonday ['floor', 'sides', 'sunday', 'wall', 'road', 'horseback', 'saturday', 'board', 'ground', 'entering']\\nsunday ['saturday', 'wall', 'kitchen', 'stone', 'sea', 'garden', 'hall', 'post', 'summer', 'passage']\\nman ['gentleman', 'woman', 'lady', 'person', 'boy', 'girl', 'creature', 'fellow', 'dog', 'servant']\\nwoman ['lady', 'girl', 'gentleman', 'creature', 'man', 'servant', 'fellow', 'boy', 'soldier', 'person']\\nking ['baker', 'clergyman', 'mayor', 'bride', 'narrative', 'ghost', 'bill', 'tailor', 'cook', 'sexton']\\nqueen ['mixture', 'field', 'size', 'bowl', 'forest', 'flower', 'beef', 'glare', 'brightest', 'receipt']\\nboy ['girl', 'child', 'woman', 'lady', 'servant', 'fellow', 'baby', 'doctor', 'lad', 'gentleman']\\ngirl ['boy', 'woman', 'child', 'lady', 'creature', 'servant', 'fellow', 'baby', 'poor', 'gentleman']\\n\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "Loss: 10.337905883789062 POW = 0.75 dot norm 2 epochs\n",
    "he ['she', 'they', 'i', 'we', 'nicholas', 'everybody', 'nobody', 'it', 'newman', 'agglomeration']\n",
    "she ['he', 'they', 'i', 'barbara', 'we', 'nicholas', 'everybody', 'fanny', 'husband', 'kate']\n",
    "paris ['london', 'gallery', 'centre', 'stationed', 'park', 'capitol', 'village', 'kitchen', 'execution', 'refreshments']\n",
    "london ['kitchen', 'street', 'town', 'city', 'england', 'front', 'market', 'church', 'hall', 'west']\n",
    "table ['sofa', 'floor', 'desk', 'window', 'fire', 'wall', 'staircase', 'ground', 'fender', 'road']\n",
    "rare ['remarkable', 'serious', 'taste', 'genteel', 'romantic', 'ingenious', 'gentlemanly', 'considerable', 'deal', 'alarming']\n",
    "monday ['saturday', 'sunday', 'dinner', 'next', 'cathedral', 'morrow', 'floor', 'gazing', 'nine', 'previous']\n",
    "sunday ['saturday', 'summer', 'day', 'cathedral', 'monday', 'week', 'neighbouring', 'stage', 'stone', 'clock']\n",
    "man ['gentleman', 'woman', 'lady', 'person', 'girl', 'fellow', 'boy', 'young', 'devil', 'creature']\n",
    "woman ['man', 'lady', 'gentleman', 'girl', 'creature', 'fellow', 'young', 'boy', 'person', 'widow']\n",
    "king ['st', 'doctor', 'ghost', 'queen', 'schoolmaster', 'sol', 'bench', 'saracen', 'pastry', 'master']\n",
    "queen ['king', 'clergyman', 'landlady', 'bunch', 'mixture', 'labyrinth', 'mace', 'masterly', 'species', 'perpetual']\n",
    "boy ['child', 'girl', 'fellow', 'lad', 'woman', 'gentleman', 'man', 'creature', 'lady', 'prisoner']\n",
    "girl ['boy', 'fellow', 'child', 'woman', 'creature', 'lady', 'man', 'gentleman', 'lad', 'poor']\n",
    "\n",
    "Epoch 2/2\n",
    "\n",
    "3355452it [18:54:19, 49.30it/s]\n",
    "\n",
    "Loss: 10.741490364074707 POW = 0.75 dot no norm 2 epochs\n",
    "he ['she', 'they', 'unwarrantably', 'gilliflower', 'administer', 'gaieties', 'graymarsh', 'phil', 'ceases', 'aloof']\n",
    "she ['he', 'they', 'florence', 'everybody', 'thieve', 'edith', 'circumlocutions', 'we', 'honored', 'nobody']\n",
    "paris ['france', 'despair', 'requisition', 'fleet', 'england', 'dart', 'custody', 'parliament', 'succession', 'bevis']\n",
    "london ['england', 'town', 'our', 'itself', 'vain', 'paris', 'france', 'lincolnshire', 'italy', 'due']\n",
    "table ['ground', 'window', 'floor', 'fire', 'wall', 'road', 'board', 'sofa', 'staircase', 'box']\n",
    "rare ['mighty', 'moral', 'extensive', 'singular', 'brief', 'special', 'lively', 'female', 'mere', 'trifling']\n",
    "monday ['floor', 'sides', 'sunday', 'wall', 'road', 'horseback', 'saturday', 'board', 'ground', 'entering']\n",
    "sunday ['saturday', 'wall', 'kitchen', 'stone', 'sea', 'garden', 'hall', 'post', 'summer', 'passage']\n",
    "man ['gentleman', 'woman', 'lady', 'person', 'boy', 'girl', 'creature', 'fellow', 'dog', 'servant']\n",
    "woman ['lady', 'girl', 'gentleman', 'creature', 'man', 'servant', 'fellow', 'boy', 'soldier', 'person']\n",
    "king ['baker', 'clergyman', 'mayor', 'bride', 'narrative', 'ghost', 'bill', 'tailor', 'cook', 'sexton']\n",
    "queen ['mixture', 'field', 'size', 'bowl', 'forest', 'flower', 'beef', 'glare', 'brightest', 'receipt']\n",
    "boy ['girl', 'child', 'woman', 'lady', 'servant', 'fellow', 'baby', 'doctor', 'lad', 'gentleman']\n",
    "girl ['boy', 'woman', 'child', 'lady', 'creature', 'servant', 'fellow', 'baby', 'poor', 'gentleman']\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
