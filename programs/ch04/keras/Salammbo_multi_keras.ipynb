{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Classifier on the *Salammb√¥* Dataset with Keras\n",
    "Author: Pierre Nugues\n",
    "\n",
    "We use three classes: French, English, and German"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to import some modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the dataset\n",
    "We can read the data from a file with the svmlight format or directly create numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(\n",
    "    [[35680, 2217], [42514, 2761], [15162, 990], [35298, 2274],\n",
    "     [29800, 1865], [40255, 2606], [74532, 4805], [37464, 2396],\n",
    "     [31030, 1993], [24843, 1627], [36172, 2375], [39552, 2560],\n",
    "     [72545, 4597], [75352, 4871], [18031, 1119], [36961, 2503],\n",
    "     [43621, 2992], [15694, 1042], [36231, 2487], [29945, 2014],\n",
    "     [40588, 2805], [75255, 5062], [37709, 2643], [30899, 2126],\n",
    "     [25486, 1784], [37497, 2641], [40398, 2766], [74105, 5047],\n",
    "     [76725, 5312], [18317, 1215]\n",
    "     ])\n",
    "\n",
    "y = np.array(\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "     1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add German data and we adjust `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_de = np.array(\n",
    "    [[37599, 1771], [44565, 2116], [16156, 715], [37697, 1804],\n",
    "     [29800, 1865], [42606, 2146], [78242, 3813], [40341, 1955],\n",
    "     [31030, 1993], [26676, 1346], [39250, 1902], [41780, 2106],\n",
    "     [72545, 4597], [79195, 3988], [19020, 928]\n",
    "     ])\n",
    "\n",
    "X = np.vstack((X, X_de))\n",
    "\n",
    "y = np.array(\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "     1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "     2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the Data\n",
    "Scaling and normalizing are usually very significant with neural networks. We use sklean transformers. They consist of two main methods: `fit()` and `transform()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.998, 0.062],\n",
       "       [0.998, 0.065],\n",
       "       [0.998, 0.065],\n",
       "       [0.998, 0.064]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "normalizer = Normalizer()\n",
    "X_norm = normalizer.fit_transform(X)\n",
    "X_norm[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.031,  0.094],\n",
       "       [-0.413,  0.442],\n",
       "       [-0.462,  0.486],\n",
       "       [-0.341,  0.378]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "X_scaled = scaler.fit_transform(X_norm)\n",
    "X_scaled[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_cat = keras.utils.to_categorical(y)\n",
    "Y_cat[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set a seed to have reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a classifier equivalent to a logistic regression with `softmax`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "        layers.Dense(3, activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or with one hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.Sequential([\n",
    "        layers.Dense(10, activation='relu'),\n",
    "        # layers.Dropout(0.5),\n",
    "        layers.Dense(3, activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To try the network with one hidden layer, set `complex` to true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex = True\n",
    "if complex == True:\n",
    "    model = model2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compile and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "45/45 [==============================] - 0s 767us/step - loss: 1.0673 - accuracy: 0.4444\n",
      "Epoch 2/30\n",
      "45/45 [==============================] - 0s 731us/step - loss: 0.8887 - accuracy: 0.4000\n",
      "Epoch 3/30\n",
      "45/45 [==============================] - 0s 706us/step - loss: 0.7786 - accuracy: 0.6000\n",
      "Epoch 4/30\n",
      "45/45 [==============================] - 0s 725us/step - loss: 0.7174 - accuracy: 0.6444\n",
      "Epoch 5/30\n",
      "45/45 [==============================] - 0s 704us/step - loss: 0.6751 - accuracy: 0.6444\n",
      "Epoch 6/30\n",
      "45/45 [==============================] - 0s 696us/step - loss: 0.6429 - accuracy: 0.6667\n",
      "Epoch 7/30\n",
      "45/45 [==============================] - 0s 711us/step - loss: 0.6156 - accuracy: 0.6889\n",
      "Epoch 8/30\n",
      "45/45 [==============================] - 0s 709us/step - loss: 0.5929 - accuracy: 0.6889\n",
      "Epoch 9/30\n",
      "45/45 [==============================] - 0s 700us/step - loss: 0.5734 - accuracy: 0.6889\n",
      "Epoch 10/30\n",
      "45/45 [==============================] - 0s 712us/step - loss: 0.5559 - accuracy: 0.7556\n",
      "Epoch 11/30\n",
      "45/45 [==============================] - 0s 726us/step - loss: 0.5391 - accuracy: 0.7556\n",
      "Epoch 12/30\n",
      "45/45 [==============================] - 0s 714us/step - loss: 0.5241 - accuracy: 0.8889\n",
      "Epoch 13/30\n",
      "45/45 [==============================] - 0s 729us/step - loss: 0.5114 - accuracy: 0.8667\n",
      "Epoch 14/30\n",
      "45/45 [==============================] - 0s 721us/step - loss: 0.4984 - accuracy: 0.8667\n",
      "Epoch 15/30\n",
      "45/45 [==============================] - 0s 733us/step - loss: 0.4855 - accuracy: 0.8889\n",
      "Epoch 16/30\n",
      "45/45 [==============================] - 0s 724us/step - loss: 0.4742 - accuracy: 0.8667\n",
      "Epoch 17/30\n",
      "45/45 [==============================] - 0s 739us/step - loss: 0.4633 - accuracy: 0.8667\n",
      "Epoch 18/30\n",
      "45/45 [==============================] - 0s 714us/step - loss: 0.4497 - accuracy: 0.8444\n",
      "Epoch 19/30\n",
      "45/45 [==============================] - 0s 720us/step - loss: 0.4425 - accuracy: 0.9111\n",
      "Epoch 20/30\n",
      "45/45 [==============================] - 0s 724us/step - loss: 0.4327 - accuracy: 0.8889\n",
      "Epoch 21/30\n",
      "45/45 [==============================] - 0s 793us/step - loss: 0.4234 - accuracy: 0.9111\n",
      "Epoch 22/30\n",
      "45/45 [==============================] - 0s 701us/step - loss: 0.4140 - accuracy: 0.9333\n",
      "Epoch 23/30\n",
      "45/45 [==============================] - 0s 721us/step - loss: 0.4061 - accuracy: 0.9333\n",
      "Epoch 24/30\n",
      "45/45 [==============================] - 0s 718us/step - loss: 0.3971 - accuracy: 0.9333\n",
      "Epoch 25/30\n",
      "45/45 [==============================] - 0s 746us/step - loss: 0.3899 - accuracy: 0.9111\n",
      "Epoch 26/30\n",
      "45/45 [==============================] - 0s 718us/step - loss: 0.3837 - accuracy: 0.9333\n",
      "Epoch 27/30\n",
      "45/45 [==============================] - 0s 718us/step - loss: 0.3769 - accuracy: 0.9333\n",
      "Epoch 28/30\n",
      "45/45 [==============================] - 0s 707us/step - loss: 0.3710 - accuracy: 0.9333\n",
      "Epoch 29/30\n",
      "45/45 [==============================] - 0s 701us/step - loss: 0.3651 - accuracy: 0.9333\n",
      "Epoch 30/30\n",
      "45/45 [==============================] - 0s 705us/step - loss: 0.3595 - accuracy: 0.9333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe73ca7fc40>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_scaled, Y_cat, epochs=30, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.556,  0.675, -1.261, -0.44 , -0.341, -0.449,  0.075, -0.416,\n",
       "          0.775, -0.126],\n",
       "        [ 0.188,  0.056,  1.065, -0.406,  0.383,  0.059,  0.178, -0.213,\n",
       "         -0.737, -0.013]], dtype=float32),\n",
       " array([-0.046,  0.657, -0.352, -0.068,  0.46 , -0.192, -0.116, -0.226,\n",
       "         0.291,  0.15 ], dtype=float32),\n",
       " array([[-0.683,  0.56 ,  0.006],\n",
       "        [ 0.384, -0.662,  0.439],\n",
       "        [-0.495,  1.48 , -0.984],\n",
       "        [-0.452, -0.361,  0.553],\n",
       "        [ 0.435, -0.042, -0.605],\n",
       "        [-0.606,  0.208,  0.527],\n",
       "        [ 0.431, -0.568,  0.236],\n",
       "        [-0.315, -0.372,  0.367],\n",
       "        [-0.698, -0.585,  0.992],\n",
       "        [ 0.344,  0.185, -0.004]], dtype=float32),\n",
       " array([ 0.578, -0.563, -0.015], dtype=float32)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "### Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the probabilities to belong to the classes for all the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "Y_pred_proba = model.predict(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.634, 0.081, 0.284],\n",
       "       [0.594, 0.301, 0.105],\n",
       "       [0.551, 0.357, 0.092],\n",
       "       [0.644, 0.229, 0.128],\n",
       "       [0.668, 0.086, 0.246],\n",
       "       [0.617, 0.27 , 0.113],\n",
       "       [0.64 , 0.234, 0.125],\n",
       "       [0.673, 0.177, 0.151],\n",
       "       [0.657, 0.206, 0.137],\n",
       "       [0.524, 0.391, 0.084],\n",
       "       [0.501, 0.421, 0.078],\n",
       "       [0.618, 0.268, 0.114],\n",
       "       [0.694, 0.125, 0.181],\n",
       "       [0.626, 0.257, 0.117],\n",
       "       [0.629, 0.08 , 0.291],\n",
       "       [0.208, 0.769, 0.022],\n",
       "       [0.124, 0.865, 0.011],\n",
       "       [0.391, 0.556, 0.053],\n",
       "       [0.12 , 0.869, 0.011],\n",
       "       [0.266, 0.703, 0.031],\n",
       "       [0.089, 0.904, 0.007],\n",
       "       [0.265, 0.704, 0.031],\n",
       "       [0.048, 0.948, 0.003],\n",
       "       [0.108, 0.882, 0.009],\n",
       "       [0.051, 0.945, 0.004],\n",
       "       [0.039, 0.958, 0.003],\n",
       "       [0.134, 0.854, 0.012],\n",
       "       [0.167, 0.816, 0.017],\n",
       "       [0.082, 0.912, 0.007],\n",
       "       [0.401, 0.544, 0.055],\n",
       "       [0.008, 0.001, 0.991],\n",
       "       [0.009, 0.001, 0.99 ],\n",
       "       [0.003, 0.   , 0.996],\n",
       "       [0.01 , 0.001, 0.989],\n",
       "       [0.668, 0.086, 0.246],\n",
       "       [0.021, 0.003, 0.975],\n",
       "       [0.013, 0.002, 0.985],\n",
       "       [0.012, 0.002, 0.987],\n",
       "       [0.657, 0.206, 0.137],\n",
       "       [0.022, 0.003, 0.975],\n",
       "       [0.012, 0.002, 0.987],\n",
       "       [0.022, 0.003, 0.975],\n",
       "       [0.694, 0.125, 0.181],\n",
       "       [0.021, 0.003, 0.976],\n",
       "       [0.013, 0.002, 0.985]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(precision=3, suppress=True)\n",
    "Y_pred_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recompute it with matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.634 0.081 0.284]\n",
      " [0.594 0.301 0.105]\n",
      " [0.551 0.357 0.092]\n",
      " [0.644 0.229 0.128]], shape=(4, 3), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.activations import softmax, relu\n",
    "if complex:\n",
    "    print(softmax((relu(X_scaled@model.get_weights()[0] + model.get_weights()[1]))@model.get_weights()[2] + model.get_weights()[3])[:4])\n",
    "else:\n",
    "    print(softmax((X_scaled@model.get_weights()[0] + model.get_weights()[1]))[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 0, 2,\n",
       "       2])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(Y_pred_proba, axis=-1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss\n",
    "We recompute the loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For one observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4549896"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "- Y_cat[0] @ np.log(Y_pred_proba[0]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35218993"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-np.mean(np.log(Y_pred_proba[range(0, len(y)), y]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3522 - accuracy: 0.9333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3521899878978729, 0.9333333373069763]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_scaled, Y_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        15\n",
      "           1       1.00      1.00      1.00        15\n",
      "           2       1.00      0.80      0.89        15\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.94      0.93      0.93        45\n",
      "weighted avg       0.94      0.93      0.93        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We computed the accuracy from the training set. This is not a good practice. We should use a dedicated test set instead."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b97b11a820675205aae8f1d7f2a3f22bbd3a2c30189f44042310baf5b4cd1987"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
