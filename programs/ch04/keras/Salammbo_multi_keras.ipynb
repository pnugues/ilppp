{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Classifier on the *Salammb√¥* Dataset with Keras\n",
    "Author: Pierre Nugues\n",
    "\n",
    "We use three classes: French, English, and German"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to import some modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the dataset\n",
    "We can read the data from a file with the svmlight format or directly create numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(\n",
    "    [[35680, 2217], [42514, 2761], [15162, 990], [35298, 2274],\n",
    "     [29800, 1865], [40255, 2606], [74532, 4805], [37464, 2396],\n",
    "     [31030, 1993], [24843, 1627], [36172, 2375], [39552, 2560],\n",
    "     [72545, 4597], [75352, 4871], [18031, 1119], [36961, 2503],\n",
    "     [43621, 2992], [15694, 1042], [36231, 2487], [29945, 2014],\n",
    "     [40588, 2805], [75255, 5062], [37709, 2643], [30899, 2126],\n",
    "     [25486, 1784], [37497, 2641], [40398, 2766], [74105, 5047],\n",
    "     [76725, 5312], [18317, 1215]\n",
    "     ])\n",
    "\n",
    "y = np.array(\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "     1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add German data and we adjust `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_de = np.array(\n",
    "    [[37599, 1771], [44565, 2116], [16156, 715], [37697, 1804],\n",
    "     [29800, 1865], [42606, 2146], [78242, 3813], [40341, 1955],\n",
    "     [31030, 1993], [26676, 1346], [39250, 1902], [41780, 2106],\n",
    "     [72545, 4597], [79195, 3988], [19020, 928]\n",
    "     ])\n",
    "\n",
    "X = np.vstack((X, X_de))\n",
    "\n",
    "y = np.array(\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "     1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "     2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the Data\n",
    "Scaling and normalizing are usually very significant with neural networks. We use sklean transformers. They consist of two main methods: `fit()` and `transform()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.99807515, 0.06201605],\n",
       "       [0.99789783, 0.06480679],\n",
       "       [0.99787509, 0.06515607],\n",
       "       [0.99793128, 0.06428964]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "normalizer = Normalizer()\n",
    "X_norm = normalizer.fit_transform(X)\n",
    "X_norm[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03108396,  0.0944527 ],\n",
       "       [-0.4126595 ,  0.44232074],\n",
       "       [-0.46160343,  0.48585864],\n",
       "       [-0.34067721,  0.37785758]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "X_scaled = scaler.fit_transform(X_norm)\n",
    "X_scaled[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_cat = keras.utils.to_categorical(y)\n",
    "Y_cat[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set a seed to have reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a classifier equivalent to a logistic regression with `softmax`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-01 21:38:41.496286: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "        layers.Dense(3, activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or with one hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.Sequential([\n",
    "        layers.Dense(10, activation='relu'),\n",
    "        # layers.Dropout(0.5),\n",
    "        layers.Dense(3, activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To try the network with one hidden layer, set `complex` to true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex = True\n",
    "if complex == True:\n",
    "    model = model2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compile and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "45/45 [==============================] - 0s 785us/step - loss: 0.9813 - accuracy: 0.2667\n",
      "Epoch 2/30\n",
      "45/45 [==============================] - 0s 762us/step - loss: 0.8866 - accuracy: 0.4889\n",
      "Epoch 3/30\n",
      "45/45 [==============================] - 0s 678us/step - loss: 0.8215 - accuracy: 0.5111\n",
      "Epoch 4/30\n",
      "45/45 [==============================] - 0s 708us/step - loss: 0.7738 - accuracy: 0.8000\n",
      "Epoch 5/30\n",
      "45/45 [==============================] - 0s 699us/step - loss: 0.7500 - accuracy: 0.8444\n",
      "Epoch 6/30\n",
      "45/45 [==============================] - 0s 688us/step - loss: 0.7317 - accuracy: 0.8889\n",
      "Epoch 7/30\n",
      "45/45 [==============================] - 0s 704us/step - loss: 0.7156 - accuracy: 0.8667\n",
      "Epoch 8/30\n",
      "45/45 [==============================] - 0s 634us/step - loss: 0.7003 - accuracy: 0.8444\n",
      "Epoch 9/30\n",
      "45/45 [==============================] - 0s 677us/step - loss: 0.6859 - accuracy: 0.8444\n",
      "Epoch 10/30\n",
      "45/45 [==============================] - 0s 681us/step - loss: 0.6721 - accuracy: 0.7778\n",
      "Epoch 11/30\n",
      "45/45 [==============================] - 0s 710us/step - loss: 0.6589 - accuracy: 0.8444\n",
      "Epoch 12/30\n",
      "45/45 [==============================] - 0s 676us/step - loss: 0.6454 - accuracy: 0.8667\n",
      "Epoch 13/30\n",
      "45/45 [==============================] - 0s 681us/step - loss: 0.6328 - accuracy: 0.8000\n",
      "Epoch 14/30\n",
      "45/45 [==============================] - 0s 668us/step - loss: 0.6199 - accuracy: 0.8667\n",
      "Epoch 15/30\n",
      "45/45 [==============================] - 0s 670us/step - loss: 0.6068 - accuracy: 0.8667\n",
      "Epoch 16/30\n",
      "45/45 [==============================] - 0s 685us/step - loss: 0.5954 - accuracy: 0.8222\n",
      "Epoch 17/30\n",
      "45/45 [==============================] - 0s 680us/step - loss: 0.5831 - accuracy: 0.7556\n",
      "Epoch 18/30\n",
      "45/45 [==============================] - 0s 703us/step - loss: 0.5716 - accuracy: 0.8667\n",
      "Epoch 19/30\n",
      "45/45 [==============================] - 0s 692us/step - loss: 0.5608 - accuracy: 0.8222\n",
      "Epoch 20/30\n",
      "45/45 [==============================] - 0s 613us/step - loss: 0.5498 - accuracy: 0.8444\n",
      "Epoch 21/30\n",
      "45/45 [==============================] - 0s 643us/step - loss: 0.5385 - accuracy: 0.8889\n",
      "Epoch 22/30\n",
      "45/45 [==============================] - 0s 624us/step - loss: 0.5278 - accuracy: 0.8444\n",
      "Epoch 23/30\n",
      "45/45 [==============================] - 0s 652us/step - loss: 0.5177 - accuracy: 0.8667\n",
      "Epoch 24/30\n",
      "45/45 [==============================] - 0s 685us/step - loss: 0.5076 - accuracy: 0.8667\n",
      "Epoch 25/30\n",
      "45/45 [==============================] - 0s 692us/step - loss: 0.4980 - accuracy: 0.8667\n",
      "Epoch 26/30\n",
      "45/45 [==============================] - 0s 670us/step - loss: 0.4884 - accuracy: 0.8889\n",
      "Epoch 27/30\n",
      "45/45 [==============================] - 0s 667us/step - loss: 0.4796 - accuracy: 0.9111\n",
      "Epoch 28/30\n",
      "45/45 [==============================] - 0s 652us/step - loss: 0.4710 - accuracy: 0.8889\n",
      "Epoch 29/30\n",
      "45/45 [==============================] - 0s 699us/step - loss: 0.4623 - accuracy: 0.9111\n",
      "Epoch 30/30\n",
      "45/45 [==============================] - 0s 629us/step - loss: 0.4537 - accuracy: 0.9111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f85197cd8e0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_scaled, Y_cat, epochs=30, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.57191426,  0.60600066, -0.38973573,  0.25049552,  0.6779418 ,\n",
       "          0.58679605,  0.12810422,  0.6276153 , -0.6075459 , -1.1770915 ],\n",
       "        [-0.3518648 ,  0.32574832, -0.2183541 ,  0.477886  , -0.73888886,\n",
       "         -0.7050051 , -0.36574027,  0.6027073 ,  0.02931863,  0.55345607]],\n",
       "       dtype=float32),\n",
       " array([ 0.03520421,  0.09092899, -0.23099695, -0.09910319,  0.08919332,\n",
       "         0.3221798 ,  0.03708989, -0.04844185,  0.3929666 , -0.5140454 ],\n",
       "       dtype=float32),\n",
       " array([[-0.4739945 ,  0.21661673,  0.19615576],\n",
       "        [ 0.02035217,  0.17963284,  0.54971784],\n",
       "        [ 0.48003533, -0.19417204,  0.5744656 ],\n",
       "        [-0.47567087, -0.3352624 , -0.33981088],\n",
       "        [-0.54159695, -0.53238064,  0.5559826 ],\n",
       "        [ 0.19307546, -0.445962  ,  0.95215404],\n",
       "        [-0.39203918, -0.31261498,  0.34449145],\n",
       "        [ 0.04308302,  0.56344324, -0.41226292],\n",
       "        [-0.0287454 , -0.08729865, -0.8919198 ],\n",
       "        [-0.93765235,  1.2449181 ,  0.19932221]], dtype=float32),\n",
       " array([ 0.7199813 , -0.08942591, -0.63055545], dtype=float32)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "### Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the probabilities to belong to the classes for all the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "Y_pred_proba = model.predict(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.622, 0.236, 0.142],\n",
       "       [0.533, 0.367, 0.1  ],\n",
       "       [0.494, 0.406, 0.1  ],\n",
       "       [0.588, 0.312, 0.101],\n",
       "       [0.624, 0.247, 0.129],\n",
       "       [0.555, 0.344, 0.1  ],\n",
       "       [0.583, 0.316, 0.101],\n",
       "       [0.628, 0.271, 0.101],\n",
       "       [0.607, 0.292, 0.101],\n",
       "       [0.472, 0.429, 0.099],\n",
       "       [0.454, 0.448, 0.098],\n",
       "       [0.557, 0.343, 0.1  ],\n",
       "       [0.625, 0.266, 0.109],\n",
       "       [0.565, 0.334, 0.1  ],\n",
       "       [0.62 , 0.234, 0.147],\n",
       "       [0.24 , 0.683, 0.077],\n",
       "       [0.17 , 0.765, 0.065],\n",
       "       [0.372, 0.535, 0.093],\n",
       "       [0.167, 0.769, 0.064],\n",
       "       [0.283, 0.634, 0.083],\n",
       "       [0.137, 0.805, 0.058],\n",
       "       [0.282, 0.635, 0.083],\n",
       "       [0.088, 0.867, 0.045],\n",
       "       [0.156, 0.782, 0.062],\n",
       "       [0.091, 0.862, 0.046],\n",
       "       [0.074, 0.885, 0.041],\n",
       "       [0.179, 0.754, 0.067],\n",
       "       [0.207, 0.721, 0.072],\n",
       "       [0.129, 0.814, 0.056],\n",
       "       [0.379, 0.528, 0.093],\n",
       "       [0.004, 0.001, 0.995],\n",
       "       [0.005, 0.002, 0.994],\n",
       "       [0.001, 0.   , 0.998],\n",
       "       [0.006, 0.002, 0.993],\n",
       "       [0.624, 0.247, 0.129],\n",
       "       [0.016, 0.005, 0.979],\n",
       "       [0.008, 0.003, 0.989],\n",
       "       [0.007, 0.002, 0.991],\n",
       "       [0.607, 0.292, 0.101],\n",
       "       [0.016, 0.005, 0.978],\n",
       "       [0.007, 0.002, 0.991],\n",
       "       [0.016, 0.005, 0.979],\n",
       "       [0.625, 0.266, 0.109],\n",
       "       [0.016, 0.005, 0.979],\n",
       "       [0.008, 0.003, 0.989]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(precision=3, suppress=True)\n",
    "Y_pred_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recompute it with matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.622 0.236 0.142]\n",
      " [0.533 0.367 0.1  ]\n",
      " [0.494 0.406 0.1  ]\n",
      " [0.588 0.312 0.101]], shape=(4, 3), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.activations import softmax, relu\n",
    "if complex:\n",
    "    print(softmax((relu(X_scaled@model.get_weights()[0] + model.get_weights()[1]))@model.get_weights()[2] + model.get_weights()[3])[:4])\n",
    "else:\n",
    "    print(softmax((X_scaled@model.get_weights()[0] + model.get_weights()[1]))[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 0, 2,\n",
       "       2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(Y_pred_proba, axis=-1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss\n",
    "We recompute the loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For one observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47531605"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "- Y_cat[0] @ np.log(Y_pred_proba[0]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4451290554470486"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-np.sum(Y_cat * np.log(Y_pred_proba)) / Y_cat.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.9333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.44512906670570374, 0.9333333373069763]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_scaled, Y_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        15\n",
      "           1       1.00      1.00      1.00        15\n",
      "           2       1.00      0.80      0.89        15\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.94      0.93      0.93        45\n",
      "weighted avg       0.94      0.93      0.93        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We computed the accuracy from the training set. This is not a good practice. We should use a dedicated test set instead."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b97b11a820675205aae8f1d7f2a3f22bbd3a2c30189f44042310baf5b4cd1987"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
