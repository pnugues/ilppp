{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Classifier on the *Salammb√¥* Dataset with Keras\n",
    "Author: Pierre Nugues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to import some modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the dataset\n",
    "We can read the data from a file with the svmlight format or directly create numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(\n",
    "    [[35680, 2217], [42514, 2761], [15162, 990], [35298, 2274],\n",
    "     [29800, 1865], [40255, 2606], [74532, 4805], [37464, 2396],\n",
    "     [31030, 1993], [24843, 1627], [36172, 2375], [39552, 2560],\n",
    "     [72545, 4597], [75352, 4871], [18031, 1119], [36961, 2503],\n",
    "     [43621, 2992], [15694, 1042], [36231, 2487], [29945, 2014],\n",
    "     [40588, 2805], [75255, 5062], [37709, 2643], [30899, 2126],\n",
    "     [25486, 1784], [37497, 2641], [40398, 2766], [74105, 5047],\n",
    "     [76725, 5312], [18317, 1215]\n",
    "     ])\n",
    "\n",
    "y = np.array(\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "     1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the Data\n",
    "Scaling and normalizing are usually very significant with neural networks. We use sklean transformers. They consist of two main methods: `fit()` and `transform()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.99807515, 0.06201605],\n",
       "       [0.99789783, 0.06480679],\n",
       "       [0.99787509, 0.06515607],\n",
       "       [0.99793128, 0.06428964]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "normalizer = Normalizer()\n",
    "X_norm = normalizer.fit_transform(X)\n",
    "X_norm[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.68336574, -1.7197772 ],\n",
       "       [ 0.57376529, -0.56145427],\n",
       "       [ 0.43143908, -0.41648279],\n",
       "       [ 0.78308579, -0.77610221]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "X_scaled = scaler.fit_transform(X_norm)\n",
    "X_scaled[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set a seed to have reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a classifier equivalent to a logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-01 14:34:58.468119: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or with one hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.Sequential([\n",
    "        layers.Dense(10, activation='relu'),\n",
    "        # layers.Dropout(0.5),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To try the network with one hidden layer, set `complex` to true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex = True\n",
    "if complex == True:\n",
    "    model = model2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compile and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 0s 866us/step - loss: 0.6767 - accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6133 - accuracy: 0.5667\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.5700 - accuracy: 0.6333\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.5357 - accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.5057 - accuracy: 0.9667\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.4786 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.4535 - accuracy: 0.9667\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.4299 - accuracy: 0.9667\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4075 - accuracy: 0.9667\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3861 - accuracy: 0.9667\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3655 - accuracy: 0.9667\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3458 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3268 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3086 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2911 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2744 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2585 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2435 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2293 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2161 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9f70d16400>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_scaled, y, epochs=20, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.55642354,  0.08468036,  0.63800734, -0.34263358,  0.22274607,\n",
       "         -0.29321736, -0.26967776,  0.7637208 , -0.45235777,  0.20622009],\n",
       "        [-1.0826371 ,  0.09707326,  0.11830236,  0.29359293,  0.97577786,\n",
       "         -0.33830696, -0.27349052, -0.10712074, -0.46784666,  0.18910094]],\n",
       "       dtype=float32),\n",
       " array([ 0.43258712, -0.02275259,  0.15999052, -0.11106326,  0.33749154,\n",
       "        -0.09262392, -0.01927361,  0.09613678, -0.04616996, -0.02225743],\n",
       "       dtype=float32),\n",
       " array([[-1.2910442 ],\n",
       "        [-0.53387576],\n",
       "        [-0.46092403],\n",
       "        [ 0.14404294],\n",
       "        [ 0.6558955 ],\n",
       "        [ 0.5914618 ],\n",
       "        [ 0.6156343 ],\n",
       "        [-0.39849758],\n",
       "        [ 0.4523983 ],\n",
       "        [ 0.13522762]], dtype=float32),\n",
       " array([0.54675525], dtype=float32)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "### Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the probabilities to belong to class 1 for all the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 109ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00880286],\n",
       "       [0.16010791],\n",
       "       [0.22248226],\n",
       "       [0.09704188]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = model.predict(X_scaled)\n",
    "y_pred_proba[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recompute it with matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.00880286]\n",
      " [0.16010789]\n",
      " [0.22248225]\n",
      " [0.09704188]], shape=(4, 1), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.activations import sigmoid, relu\n",
    "\n",
    "if complex:\n",
    "    print(sigmoid((relu(X_scaled@model.get_weights()[0] + model.get_weights()[1]))@model.get_weights()[2] + model.get_weights()[3])[:4])\n",
    "else:\n",
    "    print(sigmoid((X_scaled@model.get_weights()[0] + model.get_weights()[1]))[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(y_pred_proba):\n",
    "    y_pred = np.zeros(y_pred_proba.shape[0])\n",
    "    for i in range(y_pred_proba.shape[0]):\n",
    "        if y_pred_proba[i][0] >= 0.5:\n",
    "            y_pred[i] = 1\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = predict_class(y_pred_proba)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 133ms/step - loss: 0.2089 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_scaled, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We computed the accuracy from the training set. This is not a good practice. We should use a dedicated test set instead."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b97b11a820675205aae8f1d7f2a3f22bbd3a2c30189f44042310baf5b4cd1987"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
