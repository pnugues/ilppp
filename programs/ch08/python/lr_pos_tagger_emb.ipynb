{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-of-speech tagging with logistic regression\n",
    "\n",
    "Author: Pierre Nugues\n",
    "\n",
    "A simple POS tagger using a context of five words and logistic regression. We use GloVe embeddings to represent the words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn import linear_model\n",
    "import datasets\n",
    "from context_dictorizer import ContextDictorizer, evaluate\n",
    "from ch06.python.conll_dictorizer import CoNLLDictorizer\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS = 'EWT'  # 'EWT' or 'PTB' # The English Web Treebank or the Penn Treebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CORPUS == 'EWT':\n",
    "    train_sentences, dev_sentences, test_sentences, column_names = datasets.load_ud_en_ewt()\n",
    "else:\n",
    "    train_sentences, dev_sentences, test_sentences, column_names = datasets.load_conll2009_pos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'form',\n",
       " 'lemma',\n",
       " 'upos',\n",
       " 'xpos',\n",
       " 'feats',\n",
       " 'head',\n",
       " 'deprel',\n",
       " 'head',\n",
       " 'deps',\n",
       " 'misc']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# newdoc id = weblog-juancole.com_juancole_20051126063000_ENG_20051126_063000\\n# sent_id = weblog-juancole.com_juancole_20051126063000_ENG_20051126_063000-0001\\n# newpar id = weblog-juancole.com_juancole_20051126063000_ENG_20051126_063000-p0001\\n# text = Al-Zaman : American forces killed Shaikh Abdullah al-Ani, the preacher at the mosque in the town of Qaim, near the Syrian border.\\n1\\tAl\\tAl\\tPROPN\\tNNP\\tNumber=Sing\\t0\\troot\\t0:root\\tSpaceAfter=No\\n2\\t-\\t-\\tPUNCT\\tHYPH\\t_\\t1\\tpunct\\t1:punct\\tSpaceAfter=No\\n3\\tZaman\\tZam'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictorizing the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We store the corpus word in a dictionary, where the keys are the CoNLL-U columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conll_dict = CoNLLDictorizer(column_names)\n",
    "train_dict = conll_dict.transform(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '1',\n",
       "  'form': 'Al',\n",
       "  'lemma': 'Al',\n",
       "  'upos': 'PROPN',\n",
       "  'xpos': 'NNP',\n",
       "  'feats': 'Number=Sing',\n",
       "  'head': '0:root',\n",
       "  'deprel': 'root',\n",
       "  'deps': 'SpaceAfter=No'},\n",
       " {'id': '2',\n",
       "  'form': '-',\n",
       "  'lemma': '-',\n",
       "  'upos': 'PUNCT',\n",
       "  'xpos': 'HYPH',\n",
       "  'feats': '_',\n",
       "  'head': '1:punct',\n",
       "  'deprel': 'punct',\n",
       "  'deps': 'SpaceAfter=No'},\n",
       " {'id': '3',\n",
       "  'form': 'Zaman',\n",
       "  'lemma': 'Zaman',\n",
       "  'upos': 'PROPN',\n",
       "  'xpos': 'NNP',\n",
       "  'feats': 'Number=Sing',\n",
       "  'head': '1:flat',\n",
       "  'deprel': 'flat',\n",
       "  'deps': '_'},\n",
       " {'id': '4',\n",
       "  'form': ':',\n",
       "  'lemma': ':',\n",
       "  'upos': 'PUNCT',\n",
       "  'xpos': ':',\n",
       "  'feats': '_',\n",
       "  'head': '1:punct',\n",
       "  'deprel': 'punct',\n",
       "  'deps': '_'},\n",
       " {'id': '5',\n",
       "  'form': 'American',\n",
       "  'lemma': 'American',\n",
       "  'upos': 'ADJ',\n",
       "  'xpos': 'JJ',\n",
       "  'feats': 'Degree=Pos',\n",
       "  'head': '6:amod',\n",
       "  'deprel': 'amod',\n",
       "  'deps': '_'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dict[0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract the features and we store them in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_dictorizer = ContextDictorizer(output='upos', w_size=2)\n",
    "context_dictorizer.fit(train_dict)\n",
    "# Feature and response extraction\n",
    "X_dict, y = context_dictorizer.transform(train_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print the features to check they match Table 8.1 in my book (second edition)\n",
    "We use the training step extraction with the dynamic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'form_0': '__bos__', 'form_1': '__bos__', 'form_2': 'al', 'form_3': '-', 'form_4': 'zaman'}\tPROPN\n",
      "{'form_0': '__bos__', 'form_1': 'al', 'form_2': '-', 'form_3': 'zaman', 'form_4': ':'}\tPUNCT\n",
      "{'form_0': 'al', 'form_1': '-', 'form_2': 'zaman', 'form_3': ':', 'form_4': 'american'}\tPROPN\n",
      "{'form_0': '-', 'form_1': 'zaman', 'form_2': ':', 'form_3': 'american', 'form_4': 'forces'}\tPUNCT\n",
      "{'form_0': 'zaman', 'form_1': ':', 'form_2': 'american', 'form_3': 'forces', 'form_4': 'killed'}\tADJ\n",
      "{'form_0': ':', 'form_1': 'american', 'form_2': 'forces', 'form_3': 'killed', 'form_4': 'shaikh'}\tNOUN\n",
      "{'form_0': 'american', 'form_1': 'forces', 'form_2': 'killed', 'form_3': 'shaikh', 'form_4': 'abdullah'}\tVERB\n",
      "{'form_0': 'forces', 'form_1': 'killed', 'form_2': 'shaikh', 'form_3': 'abdullah', 'form_4': 'al'}\tPROPN\n",
      "{'form_0': 'killed', 'form_1': 'shaikh', 'form_2': 'abdullah', 'form_3': 'al', 'form_4': '-'}\tPROPN\n",
      "{'form_0': 'shaikh', 'form_1': 'abdullah', 'form_2': 'al', 'form_3': '-', 'form_4': 'ani'}\tPROPN\n"
     ]
    }
   ],
   "source": [
    "#context_dictorizer.print_example(train_dict)\n",
    "for i in range(10):\n",
    "    print(str(X_dict[i]) + '\\t' + y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'form_0': '__bos__',\n",
       " 'form_1': '__bos__',\n",
       " 'form_2': 'al',\n",
       " 'form_3': '-',\n",
       " 'form_4': 'zaman'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dict[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We transform the symbols into numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vec = datasets.load_glove_vectors(dim=DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.61454  ,  0.89693  ,  0.56771  ,  0.39102  , -0.22437  ,\n",
       "        0.49035  ,  0.10868  ,  0.27411  , -0.23833  , -0.52153  ,\n",
       "        0.73551  , -0.32654  ,  0.51304  ,  0.32415  , -0.46709  ,\n",
       "        0.68051  , -0.25497  , -0.040484 , -0.54418  , -1.0548   ,\n",
       "       -0.46692  ,  0.23557  ,  0.31234  , -0.34537  ,  0.14793  ,\n",
       "       -0.53745  , -0.43215  , -0.48724  , -0.51019  , -0.9051   ,\n",
       "       -0.17919  , -0.018376 ,  0.09719  , -0.31623  ,  0.7512   ,\n",
       "        0.92236  , -0.49965  ,  0.14036  , -0.28296  , -0.97443  ,\n",
       "       -0.0094408, -0.62944  ,  0.14711  , -0.94376  ,  0.0075222,\n",
       "        0.18565  , -0.99172  ,  0.072789 , -0.18474  , -0.52901  ,\n",
       "        0.38995  , -0.45677  , -0.21932  ,  1.3723   , -0.29636  ,\n",
       "       -2.2342   , -0.36667  ,  0.04987  ,  0.63421  ,  0.53275  ,\n",
       "       -0.53955  ,  0.31398  , -0.44698  , -0.38389  ,  0.066668 ,\n",
       "       -0.02168  ,  0.20558  ,  0.59456  , -0.24892  , -0.52795  ,\n",
       "       -0.3761   ,  0.077104 ,  0.75222  , -0.2647   , -0.0587   ,\n",
       "        0.67541  , -0.16559  , -0.49278  , -0.26327  , -0.21215  ,\n",
       "        0.24317  ,  0.17006  , -0.2926   , -0.5009   , -0.56638  ,\n",
       "       -0.40377  , -0.48452  , -0.32539  ,  0.75293  ,  0.0049585,\n",
       "       -0.32115  ,  0.28899  , -0.042392 ,  0.63863  , -0.20332  ,\n",
       "       -0.46785  , -0.15661  ,  0.2179   ,  1.4143   ,  0.40034  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vec['table']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract the unique words and see if they are in GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for sentence in train_dict:\n",
    "    for word in sentence:\n",
    "        words += [word['form'].lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207224"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17111"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words = set(words)\n",
    "len(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2007"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unk_cnt = 0\n",
    "for word in unique_words:\n",
    "    if word not in glove_vec:\n",
    "        unk_cnt += 1\n",
    "unk_cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create random vectors for the special tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mark_tokens = {'__unk__': np.random.uniform(-1, 1, (1,DIM)).astype(np.float32)[0], \n",
    "               '__bos__': np.random.uniform(-1, 1, (1,DIM)).astype(np.float32)[0], \n",
    "               '__eos__': np.random.uniform(-1, 1, (1,DIM)).astype(np.float32)[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.30558416, -0.20719153,  0.9562487 , -0.3019126 , -0.547967  ,\n",
       "       -0.08337779, -0.6247664 ,  0.1445823 , -0.06643973,  0.23288693,\n",
       "        0.11315586, -0.9649046 , -0.31624758, -0.4254379 , -0.37405428,\n",
       "        0.8577804 , -0.47334865, -0.46018428, -0.5249374 , -0.27850774,\n",
       "       -0.6411228 , -0.36215857,  0.6181061 ,  0.22992958, -0.00305828,\n",
       "        0.5247872 , -0.9450432 , -0.59263706,  0.6969545 ,  0.94673496,\n",
       "        0.17516367, -0.4254662 , -0.2677989 , -0.19289763, -0.48943555,\n",
       "        0.4565137 ,  0.06892559, -0.08399918, -0.8954855 , -0.6059567 ,\n",
       "       -0.73702675, -0.37068933,  0.06296079, -0.07221411, -0.17154104,\n",
       "       -0.13912769,  0.7133528 , -0.05226912, -0.7306064 ,  0.6642804 ,\n",
       "       -0.7314352 ,  0.7373011 ,  0.732513  ,  0.22730777,  0.36284977,\n",
       "        0.45550278, -0.79514295,  0.851078  ,  0.78982085, -0.05651645,\n",
       "        0.00998254, -0.24247408, -0.7035762 , -0.90906155, -0.3698797 ,\n",
       "       -0.9981354 , -0.57340664,  0.81710875, -0.44264305,  0.76196945,\n",
       "        0.5110392 ,  0.98475367,  0.40402433,  0.6125311 , -0.10569161,\n",
       "       -0.2841269 , -0.02847338, -0.5638334 ,  0.05885834,  0.7384944 ,\n",
       "        0.5177385 , -0.01254659, -0.9921682 ,  0.9226755 ,  0.7251488 ,\n",
       "       -0.6674957 ,  0.623807  ,  0.49177378,  0.22625886,  0.8873687 ,\n",
       "       -0.65538657,  0.03668832,  0.07124102, -0.60545677,  0.31374905,\n",
       "       -0.72584856,  0.73388684, -0.3222678 , -0.55131996,  0.08272219],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mark_tokens['__unk__']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We map the words to their embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_embeddings(x_feats_words):\n",
    "    x_embeddings = []\n",
    "    for form in ['form_0', 'form_1', 'form_2', 'form_3', 'form_4']:\n",
    "        #print(X_dict[0][key])\n",
    "        if x_feats_words[form] in glove_vec:\n",
    "            x_embeddings += list(glove_vec[x_feats_words[form]])\n",
    "        elif x_feats_words[form] == '__bos__':\n",
    "            x_embeddings += list(mark_tokens['__bos__'])\n",
    "        elif x_feats_words[form] == '__eos__':\n",
    "            x_embeddings += list(mark_tokens['__eos__'])\n",
    "        else:\n",
    "            x_embeddings += list(mark_tokens['__unk__'])\n",
    "    return x_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 207224/207224 [00:08<00:00, 24300.85it/s]\n"
     ]
    }
   ],
   "source": [
    "X_emb = []\n",
    "for x_dict in tqdm(X_dict):\n",
    "    X_emb += [map_embeddings(x_dict)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.15426832,\n",
       " 0.46791613,\n",
       " 0.55827695,\n",
       " 0.048383486,\n",
       " 0.20225365,\n",
       " 0.7837949,\n",
       " 0.41214815,\n",
       " 0.2664557,\n",
       " 0.9791968,\n",
       " 0.719599,\n",
       " 0.36310297,\n",
       " 0.12455861,\n",
       " 0.3494414,\n",
       " -0.034840103,\n",
       " 0.18241648,\n",
       " 0.05140237,\n",
       " -0.7763707,\n",
       " 0.22084323,\n",
       " -0.044053063,\n",
       " 0.9380405,\n",
       " -0.86235565,\n",
       " 0.959623,\n",
       " 0.3030166,\n",
       " -0.5981812,\n",
       " -0.46362373,\n",
       " -0.33278468,\n",
       " -0.2667399,\n",
       " -0.90579313,\n",
       " 0.53356904,\n",
       " 0.31991467,\n",
       " 0.78728616,\n",
       " 0.56640106,\n",
       " 0.40221268,\n",
       " -0.65917754,\n",
       " -0.9471683,\n",
       " 0.70805454,\n",
       " 0.19053006,\n",
       " -0.6830383,\n",
       " 0.35104567,\n",
       " 0.58508676,\n",
       " -0.84287864,\n",
       " 0.18092436,\n",
       " -0.8353727,\n",
       " -0.6951879,\n",
       " 0.009115021,\n",
       " 0.058422387,\n",
       " -0.39469734,\n",
       " -0.85807425,\n",
       " 0.22544967,\n",
       " 0.012701015,\n",
       " -0.40694708,\n",
       " 0.36644873,\n",
       " 0.422661,\n",
       " -0.54022586,\n",
       " 0.07717917,\n",
       " -0.8448863,\n",
       " 0.1103071,\n",
       " 0.29149973,\n",
       " 0.95717764,\n",
       " 0.19376212,\n",
       " 0.17607318,\n",
       " 0.81135666,\n",
       " -0.021448247,\n",
       " 0.79296494,\n",
       " 0.72035646,\n",
       " 0.67124605,\n",
       " 0.4822406,\n",
       " 0.11080468,\n",
       " 0.18427423,\n",
       " 0.3139711,\n",
       " -0.07899373,\n",
       " -0.46738642,\n",
       " 0.72235656,\n",
       " -0.46379134,\n",
       " -0.67996764,\n",
       " -0.3765637,\n",
       " 0.070921645,\n",
       " -0.54888374,\n",
       " -0.6169979,\n",
       " -0.302177,\n",
       " -0.6395651,\n",
       " 0.6315441,\n",
       " -0.8942845,\n",
       " -0.82298815,\n",
       " 0.8092646,\n",
       " -0.7610056,\n",
       " -0.8964534,\n",
       " 0.14121294,\n",
       " 0.40515298,\n",
       " 0.3725422,\n",
       " 0.17728345,\n",
       " -0.8114737,\n",
       " 0.93467367,\n",
       " -0.20106569,\n",
       " 0.88132,\n",
       " -0.09206164,\n",
       " -0.70798635,\n",
       " 0.686823,\n",
       " -0.25833836,\n",
       " 0.8350616,\n",
       " 0.15426832,\n",
       " 0.46791613,\n",
       " 0.55827695,\n",
       " 0.048383486,\n",
       " 0.20225365,\n",
       " 0.7837949,\n",
       " 0.41214815,\n",
       " 0.2664557,\n",
       " 0.9791968,\n",
       " 0.719599,\n",
       " 0.36310297,\n",
       " 0.12455861,\n",
       " 0.3494414,\n",
       " -0.034840103,\n",
       " 0.18241648,\n",
       " 0.05140237,\n",
       " -0.7763707,\n",
       " 0.22084323,\n",
       " -0.044053063,\n",
       " 0.9380405,\n",
       " -0.86235565,\n",
       " 0.959623,\n",
       " 0.3030166,\n",
       " -0.5981812,\n",
       " -0.46362373,\n",
       " -0.33278468,\n",
       " -0.2667399,\n",
       " -0.90579313,\n",
       " 0.53356904,\n",
       " 0.31991467,\n",
       " 0.78728616,\n",
       " 0.56640106,\n",
       " 0.40221268,\n",
       " -0.65917754,\n",
       " -0.9471683,\n",
       " 0.70805454,\n",
       " 0.19053006,\n",
       " -0.6830383,\n",
       " 0.35104567,\n",
       " 0.58508676,\n",
       " -0.84287864,\n",
       " 0.18092436,\n",
       " -0.8353727,\n",
       " -0.6951879,\n",
       " 0.009115021,\n",
       " 0.058422387,\n",
       " -0.39469734,\n",
       " -0.85807425,\n",
       " 0.22544967,\n",
       " 0.012701015,\n",
       " -0.40694708,\n",
       " 0.36644873,\n",
       " 0.422661,\n",
       " -0.54022586,\n",
       " 0.07717917,\n",
       " -0.8448863,\n",
       " 0.1103071,\n",
       " 0.29149973,\n",
       " 0.95717764,\n",
       " 0.19376212,\n",
       " 0.17607318,\n",
       " 0.81135666,\n",
       " -0.021448247,\n",
       " 0.79296494,\n",
       " 0.72035646,\n",
       " 0.67124605,\n",
       " 0.4822406,\n",
       " 0.11080468,\n",
       " 0.18427423,\n",
       " 0.3139711,\n",
       " -0.07899373,\n",
       " -0.46738642,\n",
       " 0.72235656,\n",
       " -0.46379134,\n",
       " -0.67996764,\n",
       " -0.3765637,\n",
       " 0.070921645,\n",
       " -0.54888374,\n",
       " -0.6169979,\n",
       " -0.302177,\n",
       " -0.6395651,\n",
       " 0.6315441,\n",
       " -0.8942845,\n",
       " -0.82298815,\n",
       " 0.8092646,\n",
       " -0.7610056,\n",
       " -0.8964534,\n",
       " 0.14121294,\n",
       " 0.40515298,\n",
       " 0.3725422,\n",
       " 0.17728345,\n",
       " -0.8114737,\n",
       " 0.93467367,\n",
       " -0.20106569,\n",
       " 0.88132,\n",
       " -0.09206164,\n",
       " -0.70798635,\n",
       " 0.686823,\n",
       " -0.25833836,\n",
       " 0.8350616,\n",
       " -0.41432,\n",
       " -0.46675,\n",
       " -0.91296,\n",
       " -1.1317,\n",
       " 0.76664,\n",
       " -0.59358,\n",
       " 0.29595,\n",
       " -0.51248,\n",
       " 0.34735,\n",
       " 0.97686,\n",
       " 0.93191,\n",
       " -0.65791,\n",
       " 0.88239,\n",
       " -0.077029,\n",
       " 0.58517,\n",
       " -0.44724,\n",
       " -0.42046,\n",
       " -1.8427,\n",
       " -0.59179,\n",
       " 0.6148,\n",
       " 0.38526,\n",
       " -0.15758,\n",
       " -0.38609,\n",
       " -0.94486,\n",
       " -0.47068,\n",
       " -0.17848,\n",
       " 0.60386,\n",
       " -0.55865,\n",
       " 0.15255,\n",
       " 0.50292,\n",
       " 0.21775,\n",
       " -1.0115,\n",
       " 0.35248,\n",
       " 0.85404,\n",
       " -0.33954,\n",
       " -0.12269,\n",
       " -0.47676,\n",
       " 0.92983,\n",
       " -0.36812,\n",
       " 0.88862,\n",
       " -0.34171,\n",
       " -0.25052,\n",
       " 0.86971,\n",
       " -0.20433,\n",
       " 0.57689,\n",
       " -0.91629,\n",
       " -0.11723,\n",
       " 0.097431,\n",
       " -0.17895,\n",
       " -0.781,\n",
       " -1.1449,\n",
       " 1.1303,\n",
       " 0.96451,\n",
       " 1.2043,\n",
       " -0.7749,\n",
       " -1.7316,\n",
       " 0.2995,\n",
       " 0.58258,\n",
       " 1.0277,\n",
       " 0.61106,\n",
       " -0.54132,\n",
       " 0.20202,\n",
       " 0.80456,\n",
       " -1.8521,\n",
       " 0.40225,\n",
       " 0.082409,\n",
       " 1.0294,\n",
       " 0.63151,\n",
       " -1.5753,\n",
       " 1.0125,\n",
       " 0.74329,\n",
       " -0.43693,\n",
       " -0.83032,\n",
       " -1.8695,\n",
       " 0.18963,\n",
       " -0.010152,\n",
       " -0.085902,\n",
       " -1.1551,\n",
       " -0.81038,\n",
       " 0.70703,\n",
       " 1.2529,\n",
       " -0.34243,\n",
       " -0.79822,\n",
       " -0.90024,\n",
       " -0.82239,\n",
       " -0.067554,\n",
       " -0.22919,\n",
       " 0.22274,\n",
       " 0.68071,\n",
       " 0.51051,\n",
       " -0.43398,\n",
       " 0.048717,\n",
       " 0.49785,\n",
       " 0.38527,\n",
       " -0.65062,\n",
       " 0.3385,\n",
       " 0.017321,\n",
       " -0.84962,\n",
       " 0.62581,\n",
       " -0.63767,\n",
       " -1.2557,\n",
       " 0.61036,\n",
       " 0.56793,\n",
       " -0.96596,\n",
       " -0.45249,\n",
       " -0.071696,\n",
       " 0.57122,\n",
       " -0.31292,\n",
       " -0.43814,\n",
       " 0.90622,\n",
       " 0.06961,\n",
       " -0.053104,\n",
       " 0.25029,\n",
       " 0.27841,\n",
       " 0.77724,\n",
       " 0.26329,\n",
       " 0.56874,\n",
       " -1.1171,\n",
       " -0.078268,\n",
       " -0.51317,\n",
       " 0.8071,\n",
       " 0.99214,\n",
       " 0.22753,\n",
       " 1.0847,\n",
       " 0.88292,\n",
       " 0.17221,\n",
       " -0.68686,\n",
       " -0.86467,\n",
       " -0.80003,\n",
       " -0.34738,\n",
       " -0.044074,\n",
       " -0.30444,\n",
       " 0.23406,\n",
       " 0.28592,\n",
       " 0.060548,\n",
       " -0.65477,\n",
       " -0.039738,\n",
       " 0.74878,\n",
       " -0.46471,\n",
       " 0.063023,\n",
       " -0.16519,\n",
       " -1.2217,\n",
       " -0.089479,\n",
       " -0.8125,\n",
       " 0.27615,\n",
       " -0.13841,\n",
       " -0.76667,\n",
       " -0.96974,\n",
       " 0.83123,\n",
       " -0.77639,\n",
       " -1.3327,\n",
       " -0.28732,\n",
       " -0.053684,\n",
       " 1.1735,\n",
       " -1.1795,\n",
       " -2.7519,\n",
       " 0.45359,\n",
       " 1.1984,\n",
       " 2.8203,\n",
       " 0.060114,\n",
       " 0.32296,\n",
       " 0.19097,\n",
       " 0.3459,\n",
       " -0.41503,\n",
       " 0.1515,\n",
       " 0.38148,\n",
       " 1.619,\n",
       " 0.9929,\n",
       " -0.82549,\n",
       " -0.098692,\n",
       " 0.74449,\n",
       " -0.38602,\n",
       " -1.0004,\n",
       " -1.305,\n",
       " -0.31269,\n",
       " -0.57625,\n",
       " 0.14095,\n",
       " -0.80269,\n",
       " -1.4714,\n",
       " -0.48014,\n",
       " 1.1993,\n",
       " -0.48561,\n",
       " 0.40496,\n",
       " -0.032867,\n",
       " -2.051,\n",
       " 0.18284,\n",
       " -0.2723,\n",
       " 0.043287,\n",
       " 0.066801,\n",
       " -0.62832,\n",
       " -0.05854,\n",
       " 0.28253,\n",
       " -0.083276,\n",
       " -0.022234,\n",
       " -0.55914,\n",
       " 0.24586,\n",
       " 0.36052,\n",
       " -1.5877,\n",
       " 0.76984,\n",
       " -0.64998,\n",
       " -0.59696,\n",
       " -0.43824,\n",
       " -0.39584,\n",
       " -0.5359,\n",
       " -0.51357,\n",
       " -0.24011,\n",
       " -0.061852,\n",
       " -0.17867,\n",
       " -0.094222,\n",
       " 1.0021,\n",
       " 0.21925,\n",
       " 0.16657,\n",
       " 0.29369,\n",
       " 0.085595,\n",
       " 0.25774,\n",
       " -0.48557,\n",
       " 0.21938,\n",
       " -0.90711,\n",
       " -1.2722,\n",
       " 0.6312,\n",
       " 0.12715,\n",
       " 0.087112,\n",
       " -0.058418,\n",
       " 0.29003,\n",
       " 0.17193,\n",
       " 0.46309,\n",
       " 0.95023,\n",
       " 0.75822,\n",
       " 0.18329,\n",
       " 0.25733,\n",
       " -0.05799,\n",
       " -0.57152,\n",
       " 0.11532,\n",
       " -0.34503,\n",
       " 0.1056,\n",
       " 0.10168,\n",
       " -0.43618,\n",
       " 0.52942,\n",
       " -0.52225,\n",
       " -0.95403,\n",
       " -0.089679,\n",
       " 0.72208,\n",
       " 0.21988,\n",
       " 0.00017535,\n",
       " 0.2644,\n",
       " -0.71692,\n",
       " 0.13899,\n",
       " -0.40902,\n",
       " 0.61542,\n",
       " 0.82026,\n",
       " -0.64768,\n",
       " -0.16289,\n",
       " 0.46184,\n",
       " 0.57048,\n",
       " -0.32807,\n",
       " 0.79894,\n",
       " -0.40688,\n",
       " 0.38922,\n",
       " -0.034797,\n",
       " 0.40011,\n",
       " 0.036714,\n",
       " -0.82754,\n",
       " 0.15279,\n",
       " 0.090309,\n",
       " 0.0043836,\n",
       " -0.037419,\n",
       " 0.16745,\n",
       " 0.23534,\n",
       " -0.42818,\n",
       " 1.0743,\n",
       " 0.59741,\n",
       " 0.65457,\n",
       " 1.5709,\n",
       " -0.57793,\n",
       " 0.55591,\n",
       " -0.31613,\n",
       " -0.55388,\n",
       " -0.31922,\n",
       " -0.63708,\n",
       " 0.0172,\n",
       " 0.48531,\n",
       " -0.85188,\n",
       " -0.62496,\n",
       " -0.67358,\n",
       " 0.014943,\n",
       " -0.74863,\n",
       " -0.2088,\n",
       " 0.39618,\n",
       " -0.65579,\n",
       " 0.57722,\n",
       " 1.3108,\n",
       " 0.70264,\n",
       " 0.55869,\n",
       " -0.015651,\n",
       " -0.37304,\n",
       " -0.56974,\n",
       " 0.68031,\n",
       " -0.60318,\n",
       " -0.03108,\n",
       " 0.93081]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_emb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_emb_scaled = scaler.fit_transform(X_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = linear_model.LogisticRegression(max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierre/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=500)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = classifier.fit(X_emb, y)\n",
    "model = classifier.fit(X_emb_scaled, y)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the test corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first dictorize the test corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '1',\n",
       "  'form': 'What',\n",
       "  'lemma': 'what',\n",
       "  'upos': 'PRON',\n",
       "  'xpos': 'WP',\n",
       "  'feats': 'PronType=Int',\n",
       "  'head': '0:root',\n",
       "  'deprel': 'root',\n",
       "  'deps': '_'},\n",
       " {'id': '2',\n",
       "  'form': 'if',\n",
       "  'lemma': 'if',\n",
       "  'upos': 'SCONJ',\n",
       "  'xpos': 'IN',\n",
       "  'feats': '_',\n",
       "  'head': '4:mark',\n",
       "  'deprel': 'mark',\n",
       "  'deps': '_'},\n",
       " {'id': '3',\n",
       "  'form': 'Google',\n",
       "  'lemma': 'Google',\n",
       "  'upos': 'PROPN',\n",
       "  'xpos': 'NNP',\n",
       "  'feats': 'Number=Sing',\n",
       "  'head': '4:nsubj',\n",
       "  'deprel': 'nsubj',\n",
       "  'deps': '_'},\n",
       " {'id': '4',\n",
       "  'form': 'Morphed',\n",
       "  'lemma': 'morph',\n",
       "  'upos': 'VERB',\n",
       "  'xpos': 'VBD',\n",
       "  'feats': 'Mood=Ind|Tense=Past|VerbForm=Fin',\n",
       "  'head': '1:advcl:if',\n",
       "  'deprel': 'advcl',\n",
       "  'deps': '_'},\n",
       " {'id': '5',\n",
       "  'form': 'Into',\n",
       "  'lemma': 'into',\n",
       "  'upos': 'ADP',\n",
       "  'xpos': 'IN',\n",
       "  'feats': '_',\n",
       "  'head': '6:case',\n",
       "  'deprel': 'case',\n",
       "  'deps': '_'}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict = conll_dict.transform(test_sentences)\n",
    "test_dict[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dict_test, y_test = context_dictorizer.transform(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'form_0': '__bos__',\n",
       "  'form_1': '__bos__',\n",
       "  'form_2': 'what',\n",
       "  'form_3': 'if',\n",
       "  'form_4': 'google'},\n",
       " {'form_0': '__bos__',\n",
       "  'form_1': 'what',\n",
       "  'form_2': 'if',\n",
       "  'form_3': 'google',\n",
       "  'form_4': 'morphed'},\n",
       " {'form_0': 'what',\n",
       "  'form_1': 'if',\n",
       "  'form_2': 'google',\n",
       "  'form_3': 'morphed',\n",
       "  'form_4': 'into'},\n",
       " {'form_0': 'if',\n",
       "  'form_1': 'google',\n",
       "  'form_2': 'morphed',\n",
       "  'form_3': 'into',\n",
       "  'form_4': 'googleos'},\n",
       " {'form_0': 'google',\n",
       "  'form_1': 'morphed',\n",
       "  'form_2': 'into',\n",
       "  'form_3': 'googleos',\n",
       "  'form_4': '?'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dict_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PRON', 'SCONJ', 'PROPN', 'VERB', 'ADP']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 25455/25455 [00:01<00:00, 19708.46it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test_emb = []\n",
    "for x_dict in tqdm(X_dict_test):\n",
    "    X_test_emb += [map_embeddings(x_dict)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_emb_scaled = scaler.transform(X_test_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(X_test_emb_scaled)\n",
    "#y_test_pred = model.predict(X_test_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PRON', 'SCONJ', 'VERB', 'VERB', 'ADP', 'NOUN', 'PUNCT', 'PRON',\n",
       "       'SCONJ', 'VERB', 'VERB', 'ADP', 'PRON', 'NOUN', 'PUNCT', 'NOUN',\n",
       "       'PUNCT', 'CCONJ', 'ADV', 'NOUN'], dtype='<U5')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.884737772539776"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy when nonscaled. Would require more experiments\n",
    "# 0.8837949322333529"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Applying the model to sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['That round table might collapse .',\n",
    "             'The man can learn well .',\n",
    "             'The man can swim well .',\n",
    "             'The man can simwo .',\n",
    "             'that round table might collapsex .']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create CoNLL-like sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_conll(sentence):\n",
    "    \"\"\"\n",
    "    Convert a sentence to a CoNLL dict\n",
    "    :param sentence:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    column_names = ['id', 'form']\n",
    "    sentence = list(enumerate(sentence.split(), start=1))\n",
    "    conll_cols = ''\n",
    "    for tuple in sentence:\n",
    "        conll_cols += str(tuple[0]) + '\\t' + tuple[1] + '\\n'\n",
    "\n",
    "    conll_dict = CoNLLDictorizer(column_names)\n",
    "    sent_dict = conll_dict.transform(conll_cols)\n",
    "    return sent_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '1', 'form': 'That'},\n",
       " {'id': '2', 'form': 'round'},\n",
       " {'id': '3', 'form': 'table'},\n",
       " {'id': '4', 'form': 'might'},\n",
       " {'id': '5', 'form': 'collapse'},\n",
       " {'id': '6', 'form': '.'}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_to_conll(sentences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we tag them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That round table might collapse .\n",
      "['DET' 'ADJ' 'NOUN' 'AUX' 'VERB' 'PUNCT']\n",
      "The man can learn well .\n",
      "['DET' 'NOUN' 'AUX' 'VERB' 'ADV' 'PUNCT']\n",
      "The man can swim well .\n",
      "['DET' 'NOUN' 'AUX' 'VERB' 'ADV' 'PUNCT']\n",
      "The man can simwo .\n",
      "['DET' 'NOUN' 'AUX' 'VERB' 'PUNCT']\n",
      "that round table might collapsex .\n",
      "['DET' 'ADJ' 'NOUN' 'VERB' 'VERB' 'PUNCT']\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    sentence_conll = sentence_to_conll(sentence.lower().strip())\n",
    "    X_feats, y = context_dictorizer.transform([sentence_conll], training_step=False)\n",
    "    X = []\n",
    "    for x_dict in X_feats:\n",
    "        X += [map_embeddings(x_dict)]\n",
    "    print(sentence)\n",
    "    print(model.predict(scaler.transform(X)))\n",
    "    #print(model.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
